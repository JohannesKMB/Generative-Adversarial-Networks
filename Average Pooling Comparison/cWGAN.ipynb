{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam, SGD\n",
    "import torch\n",
    "import numpy as np\n",
    "import ot\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from Util_mixture import *\n",
    "from sklearn.datasets import fetch_openml\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Critic_(nn.Module):\n",
    "    def __init__(self, img_dim, target_dim):\n",
    "        super().__init__()\n",
    "        self.crit = nn.Sequential(\n",
    "        nn.Linear(img_dim + img_dim + target_dim, 256),\n",
    "        nn.LeakyReLU(0.1),\n",
    "        nn.Linear(256,256),\n",
    "        nn.LeakyReLU(0.1),\n",
    "        nn.Linear(256,256),\n",
    "        nn.LeakyReLU(0.1),\n",
    "        nn.Linear(256,256),\n",
    "        nn.LeakyReLU(0.05),\n",
    "        nn.Linear(256,1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, t, batch_size=64):\n",
    "        x = torch.cat((x, t.view(batch_size, -1)), dim=1)\n",
    "        return self.crit(x)\n",
    "    \n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim, img_dim, target_dim):\n",
    "        super().__init__()\n",
    "        self.gen = nn.Sequential(\n",
    "            nn.Linear(z_dim + target_dim, 256),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(256,256),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(256, img_dim),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "            return self.gen(x)\n",
    "        \n",
    "def create_GAN(mat_dim, z_dim):\n",
    "    image_dim = mat_dim ** 2\n",
    "    target_dim = int(mat_dim ** 2 / 4)    \n",
    "    crit = Critic(image_dim, target_dim).to(device)\n",
    "    gen = Generator(z_dim, image_dim, target_dim).to(device)\n",
    "    \n",
    "    return crit, gen\n",
    "\n",
    "def loss_W(crit_1, crit_2, crit_3):\n",
    "    return torch.mean(1/2 * (crit_1 + crit_2) - crit_3)\n",
    "\n",
    "def loss_Drift(crit):\n",
    "    return torch.mean(crit ** 2)\n",
    "\n",
    "def loss_gp(fake1, fake2, real, rtarget, crit, batch_size):\n",
    "    t = rtarget.clone().detach().requires_grad_(True)\n",
    "    eps = torch.rand(1).to(device)\n",
    "    XX1 = torch.cat((eps * real + (1 - eps) * fake1, eps * fake1 + (1 - eps) * fake2), dim=1)\n",
    "    XX2 = torch.cat((eps * fake1 + (1 - eps) * fake1, eps * real + (1 - eps) * fake2), dim=1)\n",
    "    D1 = crit(XX1, t, batch_size)\n",
    "    D2 = crit(XX2, t, batch_size)\n",
    "\n",
    "    Gamma1 = torch.autograd.grad(\n",
    "        inputs=[XX1, t], \n",
    "        outputs=D1,\n",
    "        grad_outputs=torch.ones_like(D1),\n",
    "        create_graph=True,\n",
    "        retain_graph=True)[0]\n",
    "    Gamma2 = torch.autograd.grad(\n",
    "        inputs=[XX2, t], \n",
    "        outputs=D2,\n",
    "        grad_outputs=torch.ones_like(D2),\n",
    "        create_graph=True,\n",
    "        retain_graph=True)[0]\n",
    "    \n",
    "    Gamma = 1/2 * (Gamma1 + Gamma2)\n",
    "    \n",
    "    return torch.mean((torch.norm(Gamma, p=2) - 1) ** 2)\n",
    "\n",
    "def gl(models, data_loader, opt_gen, opt_crit, z_dim, mat_dim, n_critic=10):\n",
    "    \n",
    "    crit = models[0]\n",
    "    gen = models[1]\n",
    "    for batch_id, (real, rtarget) in enumerate(data_loader()):    \n",
    "        batch_size = real.shape[0]\n",
    "        real = real.view(-1, mat_dim ** 2).to(device)\n",
    "        rtarget = rtarget.view(-1, int(mat_dim ** 2 / 4)).to(device)\n",
    "\n",
    "        noise1 = torch.randn(batch_size, z_dim).to(device)\n",
    "        noise2 = torch.randn(batch_size, z_dim).to(device)\n",
    "        noise1 = torch.cat((noise1, rtarget.view(batch_size,-1)), dim=1)\n",
    "        noise2 = torch.cat((noise2, rtarget.view(batch_size,-1)), dim=1)\n",
    "\n",
    "        fake1 = gen(noise1)\n",
    "        fake2 = gen(noise2)\n",
    "\n",
    "        inp1 = torch.cat((real, fake1), dim=1)\n",
    "        inp2 = torch.cat((fake2, real), dim=1)\n",
    "        inp3 = torch.cat((fake1, fake2), dim=1)\n",
    "\n",
    "        crit1 = crit(inp1, rtarget, batch_size).view(-1)\n",
    "        crit2 = crit(inp2, rtarget, batch_size).view(-1)\n",
    "        crit3 = crit(inp3, rtarget, batch_size).view(-1)\n",
    "\n",
    "        L_G = loss_W(crit1, crit2, crit3) \n",
    "        gen.zero_grad()\n",
    "\n",
    "        L_G.backward()\n",
    "        opt_gen.step()\n",
    "        for _ in range(n_critic):\n",
    "            noise1 = torch.randn(batch_size, z_dim).to(device)\n",
    "            noise2 = torch.randn(batch_size, z_dim).to(device)\n",
    "\n",
    "            noise1 = torch.cat((noise1, rtarget.view(batch_size,-1)), dim=1).to(device)\n",
    "            noise2 = torch.cat((noise2, rtarget.view(batch_size,-1)), dim=1).to(device)\n",
    "\n",
    "            fake1 = gen(noise1)\n",
    "            fake2 = gen(noise2)\n",
    "\n",
    "            inp1 = torch.cat((real, fake1), dim=1)\n",
    "            inp2 = torch.cat((fake2, real), dim=1)\n",
    "            inp3 = torch.cat((fake1, fake2), dim=1)\n",
    "            inp4 = torch.cat((real, real), dim=1)\n",
    "\n",
    "            crit1 = crit(inp1, rtarget, batch_size).view(-1)\n",
    "            crit2 = crit(inp2, rtarget, batch_size).view(-1)\n",
    "            crit3 = crit(inp3, rtarget, batch_size).view(-1)\n",
    "            crit4 = crit(inp4, rtarget, batch_size).view(-1)\n",
    "            \n",
    "            a = loss_W(crit1, crit2, crit3)\n",
    "            b = loss_Drift(crit4)\n",
    "            c = loss_gp(fake1, fake2, real, rtarget, crit, batch_size)\n",
    "\n",
    "            L_D = (\n",
    "           -a + 1e-3 * b + 10 * c\n",
    "                )\n",
    "\n",
    "            crit.zero_grad()\n",
    "            L_D.backward(retain_graph=True)\n",
    "            opt_crit.step()\n",
    "            \n",
    "            \n",
    "    return L_D.item(), -a.item(), b.item(), c.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(testing_ys, mat_dim, z_dim):\n",
    "    \n",
    "    loss_Ds, loss_Ws, loss_drifts, loss_gps = [], [], [], []\n",
    "    models = create_GAN(mat_dim, z_dim)\n",
    "    params  = []\n",
    "    for i in range(len(models)):\n",
    "        params += models[i].parameters()\n",
    "\n",
    "    lr = 1e-5\n",
    "    opt_crit = Adam(models[0].parameters(), lr=lr, betas=(0.5, 0.9), weight_decay=10e-4)\n",
    "    opt_gen = Adam(models[1].parameters(), lr=lr, betas=(0.5, 0.9), weight_decay=10e-4) \n",
    "\n",
    "    num_epochs = 100    \n",
    "    batch_size = 64    \n",
    "    num_samples_per_epoch = 2048\n",
    "    prog_bar = tqdm(total=num_epochs)\n",
    "    for i in range(num_epochs):\n",
    "        data_loader = get_epoch_data_loader_new(num_samples_per_epoch, batch_size, mat_dim)\n",
    "        loss_D, loss_W, loss_drift, loss_gp = gl(models, data_loader, opt_gen, opt_crit, z_dim, mat_dim)\n",
    "        loss_Ds += [loss_D]\n",
    "        loss_Ws += [loss_W]\n",
    "        loss_drifts += [loss_drift]\n",
    "        loss_gps += [loss_gp]\n",
    "        \n",
    "        prog_bar.set_description('loss: {:.4f}'.format(loss_D))\n",
    "        prog_bar.update()\n",
    "    prog_bar.close()    \n",
    "\n",
    "    return models, loss_Ds, loss_Ws, loss_drifts, loss_gps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(testing_ys, mat_dim, z_dim):\n",
    "    result = []\n",
    "    testing_x_per_y = 2048\n",
    "    weights1, weights2 = np.ones((testing_x_per_y,)) / testing_x_per_y, np.ones((testing_x_per_y,)) / testing_x_per_y\n",
    "\n",
    "    weights1 = weights1.astype(np.float64)\n",
    "    weights2 = weights2.astype(np.float64)\n",
    "    w1 = 0.\n",
    "\n",
    "    testing_num_y = len(testing_ys)\n",
    "    prog_bar = tqdm(total=testing_num_y)\n",
    "    prog_bar.set_description('Computing Wasserstein distances')\n",
    "    for i, y in enumerate(testing_ys):\n",
    "        true_posterior_samples = draw_posterior_matrix(y, mat_dim, testing_x_per_y)\n",
    "        inflated_ys = y.flatten()[None, :].repeat(testing_x_per_y, 1)\n",
    "        true_post = true_posterior_samples.reshape(-1, mat_dim ** 2)\n",
    "        noise1 = torch.randn(testing_x_per_y, z_dim).to(device)\n",
    "        rtarget = inflated_ys\n",
    "        testinp = torch.cat((noise1, rtarget.view(testing_x_per_y, -1)), dim=1)\n",
    "\n",
    "        samples1 = models[1](testinp).detach().cpu().numpy()\n",
    "        samples1 = samples1.reshape(testing_x_per_y, mat_dim* mat_dim)\n",
    "        result += [samples1]\n",
    "        M1 = ot.dist(torch.tensor(samples1, dtype=torch.float32), true_post)\n",
    "        w1 += ot.emd2(weights1, weights2, M1)\n",
    "        prog_bar.set_description('W: {:.3f}'.format(w1 / (i + 1)))\n",
    "        prog_bar.update()\n",
    "    prog_bar.close()\n",
    "    print('Wasserstein:', w1 / testing_num_y)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_list = []\n",
    "testing_num_y = 100\n",
    "mat_dim = 8\n",
    "z_dim = mat_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_xs = draw_x_mats(100, mat_dim)                \n",
    "testing_ys = forward_mat(testing_xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: -0.0069:   1%|          | 1/100 [00:06<10:58,  6.65s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-d435ee53dd94>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_Ds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_Ws\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_drifts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_gps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_and_eval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtesting_ys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmat_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-5-1ca8dc4f2073>\u001b[0m in \u001b[0;36mtrain_and_eval\u001b[1;34m(testing_ys, mat_dim, z_dim)\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[0mdata_loader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_epoch_data_loader_new\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_samples_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmat_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m         \u001b[0mloss_D\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_W\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_drift\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_gp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopt_gen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopt_crit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmat_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m         \u001b[0mloss_Ds\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mloss_D\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[0mloss_Ws\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mloss_W\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-424687a644b9>\u001b[0m in \u001b[0;36mgl\u001b[1;34m(models, data_loader, opt_gen, opt_crit, z_dim, mat_dim, n_critic)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m         \u001b[0mfake1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnoise1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m         \u001b[0mfake2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnoise2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[0minp1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfake1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-424687a644b9>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     35\u001b[0m         )\n\u001b[0;32m     36\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcreate_GAN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmat_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[0mimage_dim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmat_dim\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    117\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\activation.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    712\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    713\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 714\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnegative_slope\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    715\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    716\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mleaky_relu\u001b[1;34m(input, negative_slope, inplace)\u001b[0m\n\u001b[0;32m   1376\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleaky_relu_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnegative_slope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1377\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1378\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnegative_slope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1379\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1380\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "models, loss_Ds, loss_Ws, loss_drifts, loss_gps = train(testing_ys, mat_dim, z_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Wasserstein distances:   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 8, 8]) torch.Size([100, 4, 4])\n",
      "4\n",
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 13.918:   1%|          | 1/100 [00:02<03:28,  2.11s/it]              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.756:   2%|▏         | 2/100 [00:04<03:27,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.963:   3%|▎         | 3/100 [00:06<03:24,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.938:   4%|▍         | 4/100 [00:08<03:20,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.771:   5%|▌         | 5/100 [00:10<03:18,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.712:   6%|▌         | 6/100 [00:12<03:15,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.774:   7%|▋         | 7/100 [00:14<03:11,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.569:   8%|▊         | 8/100 [00:16<03:06,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.561:   9%|▉         | 9/100 [00:18<03:06,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.766:  10%|█         | 10/100 [00:20<03:03,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.729:  11%|█         | 11/100 [00:22<03:02,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.706:  12%|█▏        | 12/100 [00:24<03:01,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.659:  13%|█▎        | 13/100 [00:26<02:59,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.765:  14%|█▍        | 14/100 [00:28<02:58,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.774:  15%|█▌        | 15/100 [00:31<02:57,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.907:  16%|█▌        | 16/100 [00:33<02:57,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.885:  17%|█▋        | 17/100 [00:35<02:54,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.890:  18%|█▊        | 18/100 [00:37<02:50,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.879:  19%|█▉        | 19/100 [00:39<02:51,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.830:  20%|██        | 20/100 [00:41<02:49,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.770:  21%|██        | 21/100 [00:43<02:44,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.711:  22%|██▏       | 22/100 [00:45<02:40,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.718:  23%|██▎       | 23/100 [00:47<02:39,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.688:  24%|██▍       | 24/100 [00:49<02:36,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.678:  25%|██▌       | 25/100 [00:51<02:33,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.672:  26%|██▌       | 26/100 [00:53<02:31,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.712:  27%|██▋       | 27/100 [00:56<02:32,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.714:  28%|██▊       | 28/100 [00:58<02:30,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.715:  29%|██▉       | 29/100 [01:00<02:27,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.705:  30%|███       | 30/100 [01:02<02:23,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.702:  31%|███       | 31/100 [01:04<02:20,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.697:  32%|███▏      | 32/100 [01:06<02:19,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.694:  33%|███▎      | 33/100 [01:08<02:18,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.643:  34%|███▍      | 34/100 [01:10<02:15,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.667:  35%|███▌      | 35/100 [01:12<02:15,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.704:  36%|███▌      | 36/100 [01:14<02:13,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.702:  37%|███▋      | 37/100 [01:16<02:11,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.754:  38%|███▊      | 38/100 [01:18<02:10,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.706:  39%|███▉      | 39/100 [01:20<02:07,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.748:  40%|████      | 40/100 [01:23<02:05,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.726:  41%|████      | 41/100 [01:25<02:02,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.722:  42%|████▏     | 42/100 [01:27<01:59,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.736:  43%|████▎     | 43/100 [01:29<01:57,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.720:  44%|████▍     | 44/100 [01:31<01:55,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.685:  45%|████▌     | 45/100 [01:33<01:53,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.643:  46%|████▌     | 46/100 [01:35<01:50,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.641:  47%|████▋     | 47/100 [01:37<01:48,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.625:  48%|████▊     | 48/100 [01:39<01:46,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.642:  49%|████▉     | 49/100 [01:41<01:43,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.631:  50%|█████     | 50/100 [01:43<01:41,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.625:  51%|█████     | 51/100 [01:45<01:38,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.671:  52%|█████▏    | 52/100 [01:47<01:38,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.700:  53%|█████▎    | 53/100 [01:49<01:36,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.704:  54%|█████▍    | 54/100 [01:51<01:33,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.735:  55%|█████▌    | 55/100 [01:53<01:33,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.700:  56%|█████▌    | 56/100 [01:55<01:30,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.697:  57%|█████▋    | 57/100 [01:57<01:28,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.697:  58%|█████▊    | 58/100 [02:00<01:27,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.686:  59%|█████▉    | 59/100 [02:01<01:24,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.706:  60%|██████    | 60/100 [02:04<01:22,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.696:  61%|██████    | 61/100 [02:06<01:19,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.720:  62%|██████▏   | 62/100 [02:08<01:18,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.696:  63%|██████▎   | 63/100 [02:10<01:16,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.699:  64%|██████▍   | 64/100 [02:12<01:13,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.684:  65%|██████▌   | 65/100 [02:14<01:11,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.657:  66%|██████▌   | 66/100 [02:16<01:10,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.649:  67%|██████▋   | 67/100 [02:18<01:07,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.642:  68%|██████▊   | 68/100 [02:20<01:05,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.639:  69%|██████▉   | 69/100 [02:22<01:03,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.590:  70%|███████   | 70/100 [02:24<01:00,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.577:  71%|███████   | 71/100 [02:26<00:59,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.597:  72%|███████▏  | 72/100 [02:28<00:58,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.592:  73%|███████▎  | 73/100 [02:30<00:56,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.613:  74%|███████▍  | 74/100 [02:32<00:54,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.603:  75%|███████▌  | 75/100 [02:35<00:52,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.636:  76%|███████▌  | 76/100 [02:37<00:50,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.652:  77%|███████▋  | 77/100 [02:39<00:48,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.656:  78%|███████▊  | 78/100 [02:41<00:45,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.674:  79%|███████▉  | 79/100 [02:43<00:43,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.690:  80%|████████  | 80/100 [02:45<00:42,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.683:  81%|████████  | 81/100 [02:47<00:40,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.655:  82%|████████▏ | 82/100 [02:49<00:38,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.664:  83%|████████▎ | 83/100 [02:51<00:35,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.677:  84%|████████▍ | 84/100 [02:54<00:33,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.701:  85%|████████▌ | 85/100 [02:56<00:31,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.704:  86%|████████▌ | 86/100 [02:58<00:29,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.710:  87%|████████▋ | 87/100 [03:00<00:27,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.686:  88%|████████▊ | 88/100 [03:02<00:24,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.689:  89%|████████▉ | 89/100 [03:04<00:22,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.696:  90%|█████████ | 90/100 [03:06<00:20,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.691:  91%|█████████ | 91/100 [03:08<00:18,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.695:  92%|█████████▏| 92/100 [03:10<00:16,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.716:  93%|█████████▎| 93/100 [03:12<00:14,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.724:  94%|█████████▍| 94/100 [03:14<00:12,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.709:  95%|█████████▌| 95/100 [03:16<00:10,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.672:  96%|█████████▌| 96/100 [03:19<00:08,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.668:  97%|█████████▋| 97/100 [03:21<00:06,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.688:  98%|█████████▊| 98/100 [03:23<00:04,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.681:  99%|█████████▉| 99/100 [03:25<00:02,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.688: 100%|██████████| 100/100 [03:27<00:00,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wasserstein: 14.68767139754258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "result = eval(testing_ys, mat_dim, z_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(models[1].state_dict(), r'gen_mat.pt')\n",
    "torch.save(models[0].state_dict(), r'crit_mat.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models[1].load_state_dict(torch.load(r'gen_mat.pt', map_location=torch.device('cpu')))\n",
    "models[0].load_state_dict(torch.load(r'crit_mat.pt', map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-32671eb2b24b>:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  C = forward_mat(torch.tensor(A, dtype=torch.float32).reshape(1,8,8)).reshape(4,4)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAADCElEQVR4nO3WsW0CQRBA0TuLEnDsK8L9V8AVQU4P4xwBdmDjL/FeOJNM8rW7zswC9Lz99wHAbeKEKHFClDghSpwQdXi0PB6Ps23bk06B17Tv+2Vm3q/nD+Pctm05nU5/dxWwrOt6vjX3rYUocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IWqdmfvLdb2/BH7LPjOf10MvJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEqMM3+8uyLOdnHAIv7OPWcJ2ZZx8C/IBvLUSJE6LECVHihChxQtQX/18dXbJBv0gAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAADCElEQVR4nO3WsW0CQRBA0TuLEnDsK8L9V8AVQU4P4xwBdmDjL/FeOJNM8rW7zswC9Lz99wHAbeKEKHFClDghSpwQdXi0PB6Ps23bk06B17Tv+2Vm3q/nD+Pctm05nU5/dxWwrOt6vjX3rYUocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IWqdmfvLdb2/BH7LPjOf10MvJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEqMM3+8uyLOdnHAIv7OPWcJ2ZZx8C/IBvLUSJE6LECVHihChxQtQX/18dXbJBv0gAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAFCElEQVR4nO3dvYoU2BqF4VVioJS0Bt2NmWhgZGIidGaoiZqIXoCXY+hFGIjoNSg0oiKCmIjgBCaegyi2v0HXpIP0qejMNwvmecKqYO3kZVdUe7FarQL0OfRPHwA4mDihlDihlDihlDih1OF1X25sbKy2t7dHDnLixImRnST58OHD2FaS7O/vj20tl8uxrb29vbGtzc3Nsa0kWSwWY1svX77872q12vr987Vxbm9v5/bt23/fqf7i2rVrIztJcufOnbGtJPn+/fvY1oULF8a2Hj16NLZ169atsa0kOXx4bRr/V1tbW38c9LmftVBKnFBKnFBKnFBKnFBKnFBKnFBKnFBKnFBKnFBKnFBKnFBKnFBKnFBKnFBKnFBKnFBKnFBKnFBKnFBKnFBKnFBKnFBKnFBKnFBq7d9aLxaLsX++fvHixchOkrx//35sK0lOnjw5tjX5jMDOzs7Y1vQTGj9+/BjdO4ibE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qJE0qtfWvh0KFDOXr06MhBnj9/PrKTJNevXx/bSpJ79+6NbT19+nRsa7lcjm1tbm6ObSXJr1+/RvcO4uaEUuKEUuKEUuKEUuKEUuKEUuKEUuKEUuKEUuKEUuKEUuKEUuKEUuKEUuKEUuKEUuKEUuKEUuKEUuKEUuKEUuKEUuKEUuKEUuKEUuKEUuKEUmvfStnf38+3b99GDvLmzZuRnSS5efPm2FaSXLp0aWzrwYMHY1s3btwY27p///7YVpJcuXJldO8gbk4oJU4oJU4oJU4oJU4oJU4oJU4oJU4oJU4oJU4oJU4oJU4oJU4oJU4oJU4oJU4oJU4oJU4oJU4oJU4oJU4oJU4oJU4oJU4oJU4oJU4otfY5hrdv34795f6ZM2dGdpLk9evXY1tJcuzYsbGt3d3dsa0nT56MbW1ubo5tJcmXL19G9w7i5oRS4oRS4oRS4oRS4oRS4oRS4oRS4oRS4oRS4oRS4oRS4oRS4oRS4oRS4oRS4oRS4oRS4oRS4oRS4oRS4oRS4oRS4oRS4oRS4oRS4oRSa59j2NjYyMWLF0cO8uzZs5GdJFkul2NbSXL69Omxrbt3745tXb58eWzr8ePHY1tJ8vnz59G9g7g5oZQ4oZQ4oZQ4oZQ4oZQ4oZQ4oZQ4oZQ4oZQ4oZQ4oZQ4oZQ4oZQ4oZQ4oZQ4oZQ4oZQ4oZQ4oZQ4oZQ4oZQ4oZQ4oZQ4oZQ4oZQ4odTa5xiOHDmSs2fPjhzk3bt3IztJ8vPnz7GtJHn16tXY1tWrV8e2Pn78OLa1t7c3tpUk586dG907iJsTSokTSokTSokTSokTSokTSokTSokTSokTSokTSokTSokTSokTSokTSokTSokTSokTSokTSokTSokTSokTSokTSokTSokTSokTSokTSokTSq19K+Xr16/Z3d0dOcj58+dHdpLk4cOHY1tJcvz48bGtjY2Nsa2dnZ2xrVOnTo1tJcmnT59G9w7i5oRS4oRS4oRS4oRS4oRS4oRS4oRS4oRS4oRS4oRS4oRS4oRS4oRS4oRS4oRS4oRS4oRS4oRS4oRS4oRS4oRS4oRS4oRS4oRS4oRS4oRSi9Vq9b+/XCz+k+SPuePAv9Kp1Wq19fuHa+ME/jl+1kIpcUIpcUIpcUIpcUKpPwEnAorFBJqJ4AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "z = 8 * [0]\n",
    "o = 8 * [1]\n",
    "A = torch.tensor([o,o,o,o,z,z,z,z])\n",
    "C = forward_mat(torch.tensor(A, dtype=torch.float32).reshape(1,8,8)).reshape(4,4)\n",
    "plt.figure()\n",
    "plt.tick_params(\n",
    "    axis='both',        \n",
    "    which='both',     \n",
    "    bottom=False,      \n",
    "    top=False,\n",
    "    left=False,\n",
    "    labelbottom=False,\n",
    "    labelleft=False)\n",
    "plt.imshow(A, cmap=plt.cm.gray)\n",
    "plt.savefig('mat_x.png', bbox_inches='tight')\n",
    "plt.figure()\n",
    "plt.tick_params(\n",
    "    axis='both',          \n",
    "    which='both',     \n",
    "    bottom=False,      \n",
    "    top=False,\n",
    "    left=False,\n",
    "    labelbottom=False,\n",
    "    labelleft=False)\n",
    "plt.imshow(C, cmap=plt.cm.gray)\n",
    "plt.savefig('mat_forward.png', bbox_inches='tight')\n",
    "noise1 = torch.randn(1, z_dim)\n",
    "noise = torch.cat((noise1, C.view(1,-1)), dim=1)\n",
    "test = models[1].eval()\n",
    "gen = test(noise)\n",
    "\n",
    "plt.figure()\n",
    "plt.tick_params(\n",
    "    axis='both',   \n",
    "    which='both',    \n",
    "    bottom=False, \n",
    "    top=False,\n",
    "    left=False,\n",
    "    labelbottom=False,\n",
    "    labelleft=False)\n",
    "plt.imshow(gen.detach().numpy().reshape(8,8), cmap=plt.cm.gray)\n",
    "plt.savefig('gen_mat.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = create_GAN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "154432"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in models[1].parameters() if p.requires_grad)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
