{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam, SGD\n",
    "import torch\n",
    "import numpy as np\n",
    "import ot\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from Util_mixture import *\n",
    "#from Util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x108 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mnist = fetch_openml('mnist_784')\n",
    "X = (mnist.data>127.5)*1.0\n",
    "X.shape\n",
    "plt.figure(figsize=(4,1.5))\n",
    "ax = plt.subplot(1,2,1); ax.set_title('before'); ax.imshow(X[2].reshape(28,28),cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crit 4 layer\n",
    "#gen 4 layer \n",
    "class Critic_multin_big(nn.Module):\n",
    "    def __init__(self, img_dim, target_dim):\n",
    "        super().__init__()\n",
    "        self.crit = nn.Sequential(\n",
    "        nn.Linear(img_dim + img_dim + target_dim, 256),\n",
    "        nn.LeakyReLU(0.05),\n",
    "        nn.Linear(256,256),\n",
    "        nn.LeakyReLU(0.05),\n",
    "        nn.Linear(256,256),\n",
    "        nn.LeakyReLU(0.05),\n",
    "        nn.Linear(256,256),\n",
    "        nn.LeakyReLU(0.05),\n",
    "        nn.Linear(256,1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, t, batch_size=64):\n",
    "        x = torch.cat((x, t.view(batch_size, -1)), dim=1)\n",
    "        return self.crit(x)\n",
    "class Generator_big(nn.Module):\n",
    "    def __init__(self, z_dim, img_dim, target_dim):\n",
    "        super().__init__()\n",
    "        self.gen = nn.Sequential(\n",
    "            nn.Linear(z_dim + target_dim, 256),\n",
    "            nn.LeakyReLU(0.05),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.LeakyReLU(0.05),\n",
    "            nn.Linear(256,256),\n",
    "            nn.LeakyReLU(0.05),\n",
    "            nn.Linear(256,256),\n",
    "            nn.LeakyReLU(0.05),\n",
    "            nn.Linear(256, img_dim)\n",
    "            #nn.Tanh(),\n",
    "            #nn.Sigmoid(),\n",
    "            #nn.LeakyReLU(0.1),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "            return self.gen(x)\n",
    "def create_GAN():\n",
    "    image_dim = 16\n",
    "    target_dim = 4\n",
    "    z_dim = 16\n",
    "    \n",
    "    crit = Critic_multin_big(image_dim, target_dim).to(device)\n",
    "\n",
    "    gen = Generator_big(z_dim, image_dim, target_dim).to(device)\n",
    "    \n",
    "    return crit, gen\n",
    "\n",
    "def loss_W(crit_1, crit_2, crit_3):\n",
    "    return torch.mean(1/2 * (crit_1 + crit_2) - crit_3)\n",
    "\n",
    "def loss_Drift(crit):\n",
    "    return torch.mean(crit ** 2)\n",
    "\n",
    "def loss_gp(fake1, fake2, real, rtarget, crit, batch_size):\n",
    "    t = rtarget.clone().detach().requires_grad_(True)\n",
    "    eps = torch.rand(1).to(device)\n",
    "    XX1 = torch.cat((eps * real + (1 - eps) * fake1, eps * fake1 + (1 - eps) * fake2), dim=1)\n",
    "    XX2 = torch.cat((eps * fake1 + (1 - eps) * fake1, eps * real + (1 - eps) * fake2), dim=1)\n",
    "    D1 = crit(XX1, t, batch_size)\n",
    "    D2 = crit(XX2, t, batch_size)\n",
    "    \n",
    "    '''\n",
    "    Gamma = torch.zeros_like(torch.empty(batch_size, 1))\n",
    "    for i in range(batch_size):\n",
    "        Gamma[i] = 1/2 * (torch.autograd.grad(D1[i,:], XX1[i,:])[0] + torch.autograd.grad(D2[i,:], XX2[i,:])[0])\n",
    "    '''\n",
    "    Gamma1 = torch.autograd.grad(\n",
    "        inputs=[XX1, t], \n",
    "        outputs=D1,\n",
    "        grad_outputs=torch.ones_like(D1),\n",
    "        create_graph=True,\n",
    "        retain_graph=True)[0]\n",
    "    Gamma2 = torch.autograd.grad(\n",
    "        inputs=[XX2, t], \n",
    "        outputs=D2,\n",
    "        grad_outputs=torch.ones_like(D2),\n",
    "        create_graph=True,\n",
    "        retain_graph=True)[0]\n",
    "    \n",
    "    Gamma = 1/2 * (Gamma1 + Gamma2)\n",
    "    \n",
    "    return torch.mean((torch.norm(Gamma, p=2) - 1) ** 2)\n",
    "\n",
    "def gl(models, data_loader, opt_gen, opt_crit, n_critic=5, z_dim=16):\n",
    "    \n",
    "    crit = models[0]\n",
    "    gen = models[1]\n",
    "    for batch_id, (real, rtarget) in enumerate(data_loader()):\n",
    "    \n",
    "    \n",
    "    \n",
    "        batch_size = real.shape[0]\n",
    "        #print('training data', real.shape, rtarget.shape)\n",
    "\n",
    "        real = real.view(-1, 16).to(device)\n",
    "        rtarget = rtarget.view(-1, 4).to(device)\n",
    "        #print(real.shape, rtarget.shape)\n",
    "        #print(rtarget)\n",
    "\n",
    "        noise1 = torch.randn(batch_size, z_dim).to(device)\n",
    "        noise2 = torch.randn(batch_size, z_dim).to(device)\n",
    "        #print('1', noise1.shape)\n",
    "        noise1 = torch.cat((noise1, rtarget.view(batch_size,-1)), dim=1)\n",
    "        noise2 = torch.cat((noise2, rtarget.view(batch_size,-1)), dim=1)\n",
    "        #print('1', noise1.shape)\n",
    "\n",
    "        fake1 = gen(noise1)\n",
    "        fake2 = gen(noise2)\n",
    "\n",
    "        inp1 = torch.cat((real, fake1), dim=1)\n",
    "        inp2 = torch.cat((fake1, real), dim=1)\n",
    "        inp3 = torch.cat((fake1, fake2), dim=1)\n",
    "\n",
    "        crit1 = crit(inp1, rtarget, batch_size).view(-1)\n",
    "        crit2 = crit(inp2, rtarget, batch_size).view(-1)\n",
    "        crit3 = crit(inp3, rtarget, batch_size).view(-1)\n",
    "\n",
    "        L_G = loss_W(crit1, crit2, crit3) \n",
    "        gen.zero_grad()\n",
    "\n",
    "        L_G.backward()\n",
    "        opt_gen.step()\n",
    "        for _ in range(n_critic):\n",
    "            noise1 = torch.randn(batch_size, z_dim).to(device)\n",
    "            noise2 = torch.randn(batch_size, z_dim).to(device)\n",
    "\n",
    "            noise1 = torch.cat((noise1, rtarget.view(batch_size,-1)), dim=1).to(device)\n",
    "            noise2 = torch.cat((noise2, rtarget.view(batch_size,-1)), dim=1).to(device)\n",
    "\n",
    "            fake1 = gen(noise1)\n",
    "            fake2 = gen(noise2)\n",
    "\n",
    "            inp1 = torch.cat((real, fake1), dim=1)\n",
    "            inp2 = torch.cat((fake1, real), dim=1)\n",
    "            inp3 = torch.cat((fake1, fake2), dim=1)\n",
    "            inp4 = torch.cat((real, real), dim=1)\n",
    "\n",
    "            crit1 = crit(inp1, rtarget, batch_size).view(-1)\n",
    "            crit2 = crit(inp2, rtarget, batch_size).view(-1)\n",
    "            crit3 = crit(inp3, rtarget, batch_size).view(-1)\n",
    "            crit4 = crit(inp4, rtarget, batch_size).view(-1)\n",
    "\n",
    "            L_D = (\n",
    "           -loss_W(crit1, crit2, crit3) + 1e-3 * loss_Drift(crit4) + 10 * loss_gp(fake1, fake2, real, rtarget, crit, batch_size)\n",
    "                )\n",
    "\n",
    "            crit.zero_grad()\n",
    "            L_D.backward(retain_graph=True)\n",
    "            opt_crit.step()\n",
    "            \n",
    "            \n",
    "    return -L_D.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_eval(testing_ys):\n",
    "\n",
    "\n",
    "    #models = create_SNF(4,256)\n",
    "    #4models\n",
    "    models = create_GAN()\n",
    "    params  = []\n",
    "    for i in range(len(models)):\n",
    "        params += models[i].parameters()\n",
    "\n",
    "\n",
    "\n",
    "    #optimizer = Adam(params, lr = 1e-4)\n",
    "    #1e-4 0.185\n",
    "    #2e-4 0.2\n",
    "    #5e-5 0.17\n",
    "    #3e-5 0.18\n",
    "    #7e-5 0.22\n",
    "    lr = 5e-5\n",
    "    opt_crit = Adam(models[0].parameters(), lr=lr, betas=(0.5, 0.9), weight_decay=10e-4)\n",
    "    opt_gen = Adam(models[1].parameters(), lr=lr, betas=(0.5, 0.9), weight_decay=10e-4) \n",
    "\n",
    "\n",
    "\n",
    "    #700 0.16\n",
    "    #1000 0.149\n",
    "\n",
    "    num_epochs = 50#600#8\n",
    "    \n",
    "    batch_size = 64#128\n",
    "    \n",
    "    num_samples_per_epoch = 2048#1024#6400\n",
    "\n",
    "    prog_bar = tqdm(total=num_epochs)\n",
    "    for i in range(num_epochs):\n",
    "        data_loader = get_epoch_data_loader_new(num_samples_per_epoch, batch_size)\n",
    "        loss = gl(models, data_loader, opt_gen, opt_crit)\n",
    "        #loss = train_inn_epoch(optimizer, models, params, b, data_loader, forward_map, mixture_params, convex_comb_factor=convex_comb_factor)\n",
    "\n",
    "        prog_bar.set_description('loss: {:.4f}'.format(loss))\n",
    "        prog_bar.update()\n",
    "    prog_bar.close()\n",
    "\n",
    "\n",
    "    testing_x_per_y = 2048\n",
    "\n",
    "    testing_num_y = len(testing_ys)\n",
    "    weights1, weights2 = np.ones((testing_x_per_y,)) / testing_x_per_y, np.ones((testing_x_per_y,)) / testing_x_per_y\n",
    "\n",
    "    weights1 = weights1.astype(np.float64)\n",
    "    weights2 = weights2.astype(np.float64)\n",
    "\n",
    "    w1 = 0.\n",
    "\n",
    "    prog_bar = tqdm(total=testing_num_y)\n",
    "    prog_bar.set_description('Computing Wasserstein distances')\n",
    "    for i, y in enumerate(testing_ys):\n",
    "        #true_posterior_params = get_mixture_posterior(mixture_params, forward_map, b**2 * torch.eye(DIMENSION, device=device), y)\n",
    "        #true_posterior_samples = draw_mixture_dist(true_posterior_params, testing_x_per_y).cpu().numpy()\n",
    "        true_posterior_samples = draw_mats_post(y)\n",
    "        inflated_ys = y.flatten()[None, :].repeat(testing_x_per_y, 1)\n",
    "        true_post = true_posterior_samples.reshape(-1, 16)\n",
    "        noise1 = torch.randn(testing_x_per_y, 16).to(device)\n",
    "        rtarget = inflated_ys\n",
    "        #testinp = torch.cat((noise1, rtarget.view(testing_x_per_y,-1)), dim=1)\n",
    "        testinp = torch.cat((noise1, rtarget.view(testing_x_per_y, -1)), dim=1)\n",
    "\n",
    "        samples1 = models[1](testinp).detach().cpu().numpy()\n",
    "        print(y, samples1.shape)\n",
    "        samples1 = samples1.reshape(testing_x_per_y, 4, 4)\n",
    "        print(np.round(samples1[:5]))\n",
    "\n",
    "        #samples1 = forward_SNF(torch.randn(testing_x_per_y, DIMENSION, device=device), models, b, inflated_ys, mixture_params, forward_map)[0].detach().cpu().numpy()\n",
    "        #samples2 = forward_SNF_det(torch.randn(testing_x_per_y, DIMENSION, device=device), models, b, inflated_ys, mixture_params, forward_map)[0].detach().cpu().numpy()\n",
    "        if i == 0:\n",
    "            pass\n",
    "            #make_image(true_post, samples1, 'mixtures{}_b{}_convexcomb{:.2f}_GAN.png'.format(42, 42, 42))\n",
    "            #make_image(true_posterior_samples, samples2, 'mixtures{}_b{}_convexcomb{:.2f}_det.png'.format(len(mixture_params), b, convex_comb_factor))\n",
    "        M1 = ot.dist(samples1, true_post)\n",
    "\n",
    "        w1 += ot.emd2(weights1, weights2, M1)\n",
    "        prog_bar.set_description('W: {:.3f}'.format(w1 / (i + 1)))\n",
    "        prog_bar.update()\n",
    "    prog_bar.close()\n",
    "\n",
    "    print('Wasserstein:', w1 / testing_num_y)\n",
    "\n",
    "    return w1 / testing_num_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_list = []\n",
    "\n",
    "testing_num_y = 100\n",
    "forward_map = create_forward_model(scale=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'forward keine id mehr scale=scale/i+1\\nmehr dimensionen\\nvgl inn\\nmixture parameter randomizen'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''forward keine id mehr scale=scale/i+1\n",
    "mehr dimensionen\n",
    "vgl inn\n",
    "mixture parameter randomizen'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'draw_mats' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-01a2f9ba4d1c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mtesting_xs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdraw_mats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtesting_num_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[1;31m#print('testing x', testing_xs.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;31m#5 dim gmm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'draw_mats' is not defined"
     ]
    }
   ],
   "source": [
    "for b in [0.1]:\n",
    "    for num_mixtures in [5]:\n",
    "        w = np.random.rand(5)\n",
    "        w /= w.sum()\n",
    "           \n",
    "            \n",
    "        testing_xs = draw_mats(testing_num_y, shape=4)\n",
    "        #print('testing x', testing_xs.shape)\n",
    "        #5 dim gmm\n",
    "                \n",
    "        testing_ys = forward_mat(testing_xs)\n",
    "        #print(testing_xs.shape, testing_ys.shape)\n",
    "        #100\n",
    "        \n",
    "        for convex_comb_factor in [0.]:\n",
    "            wasserstein_mean = 0\n",
    "            for i in range(1):\n",
    "                w1 = train_and_eval(testing_ys)\n",
    "                wasserstein_mean += w1\n",
    "\n",
    "            wasserstein_mean /= 1\n",
    "\n",
    "\n",
    "\n",
    "            #print('Num mixtures:', num_mixtures)\n",
    "            #print('b:', b)\n",
    "            #print('Convex combination factor:', convex_comb_factor)\n",
    "            result_dict = {}\n",
    "            result_dict['mixtures'] = mixture_params\n",
    "            result_dict['b'] = b\n",
    "            result_dict['convex_comb_factor'] = convex_comb_factor\n",
    "            result_dict['wasserstein_dist'] = wasserstein_mean\n",
    "\n",
    "            result_list.append(result_dict)\n",
    "\n",
    "np.save('./result_list.npy', result_list, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, y in enumerate(testing_ys):\n",
    "    print(i, y.shape, y.flatten().shape, y.flatten()[0])\n",
    "\n",
    "    #true_posterior_params = get_mixture_posterior(mixture_params, forward_map, b**2 * torch.eye(DIMENSION, device=device), y)\n",
    "    #true_posterior_samples = draw_mixture_dist(true_posterior_params, testing_x_per_y).cpu().numpy()\n",
    "    true_posterior_samples = draw_mats_post(y)\n",
    "    inflated_ys = y.flatten()[None, :].repeat(2048, 1)\n",
    "    print(y.flatten(), inflated_ys.shape)\n",
    "    true_post = true_posterior_samples.reshape(-1, 16)\n",
    "    noise1 = torch.randn(true_post.shape[0], 16).to(device)\n",
    "    rtarget = inflated_ys\n",
    "    #rtarget = true_post\n",
    "    #testinp = torch.cat((noise1, rtarget.view(testing_x_per_y,-1)), dim=1)\n",
    "    testinp = torch.cat((noise1, rtarget.view(2048,-1)), dim=1)\n",
    "\n",
    "    samples1 = models[1](testinp).detach().cpu().numpy()\n",
    "    print(samples1, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.choice(90, 3)\n",
    "'''\n",
    "bereits probiert:\n",
    "6 layer crit\n",
    "8 layer crit\n",
    "6 layer gen\n",
    "1000 epochs\n",
    "same same but 4048 samples\n",
    "0.2 lrelu\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([   [ [1],[2],[3] ], [ [4],[5],[6] ]   ])\n",
    "print(x)\n",
    "print(x[:,:])\n",
    "print(x[...,0])\n",
    "print(x[...])\n",
    "print(x[0,...])\n",
    "print(x[1,...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = draw_mixture_dist(mixture_params, testing_num_y)\n",
    "print(x.shape)\n",
    "print(x[:,0])\n",
    "plt.hist(x[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q25, q75 = np.percentile(x,[.25,.75])\n",
    "bin_width = 2*(q75 - q25)*len(x)**(-1/3)\n",
    "bins = round((x.max() - x.min())/bin_width)\n",
    "print(\"Freedmanâ€“Diaconis number of bins:\", bins)\n",
    "plt.hist(x, bins = bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = create_GAN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(p.numel() for p in models[1].parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(models[1].state_dict(), r'C:\\Users\\Karl\\TUB\\Master Thesis\\gen_toy_5dim_1000epochs.pt')\n",
    "torch.save(models[0].state_dict(), r'C:\\Users\\Karl\\TUB\\Master Thesis\\crit_toy_5dim_1000epochs.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.tensor([[1, 1, 1, 0], [1, 1, 0, 0], [1, 1, 0, 0], [1, 0, 1, 1]])\n",
    "A = torch.tensor([[1,1,1],[0,1,1],[1,1,1], [0,1,0]])\n",
    "A = np.round(np.random.random((4,4)))\n",
    "#A = torch.zeros(10,10)\n",
    "print(A.shape)\n",
    "if A.shape[1]%2 == 1:\n",
    "    A = torch.hstack((A, torch.zeros(A.shape[0],1)))\n",
    "if A.shape[0]%2 == 1:\n",
    "    A = torch.vstack((A, torch.zeros(A.shape[1])))\n",
    "print(A,'A')\n",
    "i, j = 0, 0\n",
    "stride = 2\n",
    "c = torch.zeros(A.shape[0]//stride, A.shape[1]//stride)\n",
    "print(c.shape)\n",
    "for _ in range(A.shape[0]):\n",
    "    for _ in range(A.shape[1]):\n",
    "        if i%2 == 0 and j%2 == 0:\n",
    "            try:\n",
    "                c[i//2, j//2] += A[i, j]\n",
    "                c[i//2, j//2] += A[i+1, j]\n",
    "                c[i//2, j//2] += A[i, j+1]\n",
    "                c[i//2, j//2] += A[i+1, j+1]\n",
    "            except:\n",
    "                print('oh noez', i,j)\n",
    "        i += 1\n",
    "        if i >= A.shape[0]:\n",
    "            i = 0\n",
    "    j += 1\n",
    "    if j >= A.shape[1]:\n",
    "            j = 0\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.MaxPool2d(3, stride=2)\n",
    "input = torch.randn(1, 1, 4, 4)\n",
    "output = m(input)\n",
    "print(output, input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#c = torch.tensor([[1,4], [1,2]])\n",
    "#c = A\n",
    "def build_candidates(c):\n",
    "    candidates = []\n",
    "    cand = []\n",
    "    for m,row in enumerate(c):\n",
    "        for n,i in enumerate(row):\n",
    "            if int(i) == 0 or int(i) == 4:\n",
    "                cand += [torch.tensor([[i * 0.25, i * 0.25], [i * 0.25, i * 0.25]])]\n",
    "            elif int(i) == 1:\n",
    "                cand += [torch.tensor([[1, 0], [0, 0]])]\n",
    "                cand += [torch.tensor([[0, 1], [0, 0]])]\n",
    "                cand += [torch.tensor([[0, 0], [1, 0]])]\n",
    "                cand += [torch.tensor([[0, 0], [0, 1]])]\n",
    "            elif int(i) == 2:\n",
    "                cand += [torch.tensor([[1, 1], [0, 0]])]\n",
    "                cand += [torch.tensor([[0, 0], [1, 1]])]\n",
    "                cand += [torch.tensor([[1, 0], [1, 0]])]\n",
    "                cand += [torch.tensor([[0, 1], [0, 1]])]\n",
    "                cand += [torch.tensor([[1, 0], [0, 1]])]\n",
    "                cand += [torch.tensor([[0, 1], [1, 0]])]\n",
    "            else:\n",
    "                cand += [torch.tensor([[1, 1], [1, 0]])]\n",
    "                cand += [torch.tensor([[1, 1], [0, 1]])]\n",
    "                cand += [torch.tensor([[1, 0], [1, 1]])]\n",
    "                cand += [torch.tensor([[0, 1], [1, 1]])]\n",
    "\n",
    "            candidates += [cand]\n",
    "            cand = []\n",
    "    return candidates\n",
    "#print(candidates)\n",
    "'''\n",
    "fin = []\n",
    "for i in candidates[0]:\n",
    "    for j in candidates[1]:\n",
    "        for k in candidates[2]:\n",
    "            for l in candidates[3]:\n",
    "                \n",
    "                upperb = np.hstack((i, j))\n",
    "                lowerb = np.hstack((k, l))\n",
    "                f = np.vstack((upperb, lowerb))\n",
    "                fin += [f]\n",
    "print(len(fin))\n",
    "for i in fin:\n",
    "    print(i)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.vstack((torch.ones(3,4),torch.zeros(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates = build_candidates(c)\n",
    "fins = build_mat(candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mat(candidates):\n",
    "    fin = []\n",
    "    for i in candidates[0]:\n",
    "        for j in candidates[1]:\n",
    "            for k in candidates[2]:\n",
    "                for l in candidates[3]:\n",
    "                    \n",
    "                    upperb = np.hstack((i, j))\n",
    "                    lowerb = np.hstack((k, l))\n",
    "                    f = np.vstack((upperb, lowerb))\n",
    "                    fin += [f]\n",
    "    return torch.tensor(fin)\n",
    "    \n",
    "def split(c):\n",
    "    cs = []\n",
    "    i,j = 0,0\n",
    "    for _ in range(c.shape[0]):\n",
    "        for _ in range(c.shape[1]):\n",
    "            if i%2 == 0 and j%2 == 0:\n",
    "                try:\n",
    "                    chat = c[i:i+2, j:j+2]\n",
    "                    cs += [chat]\n",
    "                except:\n",
    "                    print('oh noez', i,j)\n",
    "            j += 1\n",
    "            if i >= A.shape[0]:\n",
    "                i = 0\n",
    "        i += 1\n",
    "        if j >= A.shape[1]:\n",
    "                j = 0\n",
    "    return cs\n",
    "splitted = split(c)\n",
    "for splitt in splitted:\n",
    "    print(splitt)\n",
    "def divide(box):\n",
    "    \n",
    "    m = box.shape[0]\n",
    "    n = box.shape[1]\n",
    "    box1 = box[0:m//2, 0:n//2]\n",
    "    box2 = box[0:m//2, n//2:]\n",
    "    box3 = box[m//2:, 0:n//2]\n",
    "    box4 = box[m//2:, n//2:]\n",
    "    \n",
    "    return [box1, box2, box3, box4]\n",
    "nest_level = 2\n",
    "act_level = 0\n",
    "def nested(act_level, nest_level, box):\n",
    "    if act_level == nest_level:\n",
    "        return box\n",
    "    else:\n",
    "        act_level += 1\n",
    "        box = divide(box)\n",
    "        return nested(act_level, nest_level, box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finss = []\n",
    "rowc = []\n",
    "i,j = 0,0\n",
    "for chat in splitted:\n",
    "    candidates = build_candidates(chat)\n",
    "    fins = build_mat(candidates)\n",
    "    finss += [fins]\n",
    "    i += 1\n",
    "    if i > 1:\n",
    "        for mats1 in finss[0]:\n",
    "            for mats2 in finss[1]:\n",
    "                rowc += [np.vstack(mats1, mats2)]\n",
    "        finss = []\n",
    "        j += 1\n",
    "        i = 0\n",
    "    if j >= c.shape[0] // 2:\n",
    "        \n",
    "                \n",
    "            \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "math.factorial(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_candidates_shallow():\n",
    "    if end:\n",
    "        candidates = build_candidates_deep\n",
    "        fins = build_mat(candidates)\n",
    "        return fins\n",
    "    else:\n",
    "        candidates = build_candidates_shallow\n",
    "        fins = build_mat(candidates)\n",
    "        return fins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in boxlist:\n",
    "    if type(element) is list:\n",
    "        return func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "64*864*576*864"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fins = []\n",
    "c = np.array([[2,2],[2,2]])\n",
    "candidates = build_candidates(c)\n",
    "fin = build_mat(candidates)\n",
    "print(fin.reshape(-1, 16).shape)\n",
    "\n",
    "\n",
    "if False:\n",
    "    for boxxx in divide(c):\n",
    "        candidates = build_candidates(boxxx)\n",
    "        fin = build_mat(candidates)\n",
    "        fins += [fin]\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nest_level = 2\n",
    "act_level = 0\n",
    "def nested(act_level, nest_level, box):\n",
    "    if act_level == nest_level:\n",
    "        return divide(box)\n",
    "    else:\n",
    "        act_level += 1\n",
    "        try:\n",
    "            box = divide(box)\n",
    "        except:\n",
    "            \n",
    "            return nested(act_level, nest_level, box[act_level])\n",
    "print(nested(act_level, nest_level, c))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tuples(depth, n, start=0):\n",
    "    if depth == 0:\n",
    "        yield ()\n",
    "    else:\n",
    "        for x in range(start, n):\n",
    "            for t in make_tuples(depth - 1, n, x + 1):\n",
    "                yield (x,) + t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (i1, i2, i3) in make_tuples(3, 10):\n",
    "\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = 1\n",
    "def rec(box, init, divs=[]):\n",
    "    if init == 1:\n",
    "        init = 0\n",
    "        divs = []\n",
    "    if type(box) is list:\n",
    "        for b in box:\n",
    "            print(b)\n",
    "            divs.append([rec(b, init, divs)])\n",
    "    else:\n",
    "        box = divide(box)\n",
    "        \n",
    "        return rec(box, init)\n",
    "    \n",
    "    return divs\n",
    "\n",
    "print(rec(c, init))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.tensor(np.array([[2,1],[2,4]]))\n",
    "w = torch.cat([w,w])\n",
    "print(w)\n",
    "print(w.reshape(-1,2,2))\n",
    "w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.tensor(np.array([[2,1],[2,4]]))\n",
    "\n",
    "w[None, :].repeat(8, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = get_epoch_data_loader_new(1000, 32)\n",
    "for batch_id, (real, rtarget) in enumerate(h()):\n",
    "    print(batch_id, real.shape, rtarget.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.tensor([[1,2],[3,4]])\n",
    "yy = y[None, :].repeat(10, 1)\n",
    "yy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
