{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam, SGD\n",
    "import torch\n",
    "import numpy as np\n",
    "import ot\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from Util_mixture import *\n",
    "#from Util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x108 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mnist = fetch_openml('mnist_784')\n",
    "X = (mnist.data>127.5)*1.0\n",
    "X.shape\n",
    "plt.figure(figsize=(4,1.5))\n",
    "ax = plt.subplot(1,2,1); ax.set_title('before'); ax.imshow(X[2].reshape(28,28),cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crit 4 layer\n",
    "#gen 4 layer \n",
    "class Critic_multin_big(nn.Module):\n",
    "    def __init__(self, img_dim, target_dim):\n",
    "        super().__init__()\n",
    "        self.crit = nn.Sequential(\n",
    "        nn.Linear(img_dim + img_dim + target_dim, 256),\n",
    "        nn.LeakyReLU(0.1),\n",
    "        nn.Linear(256,256),\n",
    "        nn.LeakyReLU(0.1),\n",
    "        nn.Linear(256,256),\n",
    "        nn.LeakyReLU(0.1),\n",
    "        nn.Linear(256,256),\n",
    "        nn.LeakyReLU(0.05),\n",
    "        nn.Linear(256,1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, t, batch_size=64):\n",
    "        x = torch.cat((x, t.view(batch_size, -1)), dim=1)\n",
    "        return self.crit(x)\n",
    "class Generator_big(nn.Module):\n",
    "    def __init__(self, z_dim, img_dim, target_dim):\n",
    "        super().__init__()\n",
    "        self.gen = nn.Sequential(\n",
    "            nn.Linear(z_dim + target_dim, 256),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(256,256),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(256, img_dim),\n",
    "            #nn.Tanh(),\n",
    "            nn.Sigmoid(),\n",
    "            #nn.LeakyReLU(0.1),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "            return self.gen(x)\n",
    "def create_GAN(mat_dim, z_dim):\n",
    "    image_dim = mat_dim ** 2\n",
    "    target_dim = int(mat_dim ** 2 / 4)\n",
    "    \n",
    "    crit = Critic_multin_big(image_dim, target_dim).to(device)\n",
    "\n",
    "    gen = Generator_big(z_dim, image_dim, target_dim).to(device)\n",
    "    \n",
    "    return crit, gen\n",
    "\n",
    "def loss_W(crit_1, crit_2, crit_3):\n",
    "    return torch.mean(1/2 * (crit_1 + crit_2) - crit_3)\n",
    "\n",
    "def loss_Drift(crit):\n",
    "    return torch.mean(crit ** 2)\n",
    "\n",
    "def loss_gp(fake1, fake2, real, rtarget, crit, batch_size):\n",
    "    t = rtarget.clone().detach().requires_grad_(True)\n",
    "    eps = torch.rand(1).to(device)\n",
    "    XX1 = torch.cat((eps * real + (1 - eps) * fake1, eps * fake1 + (1 - eps) * fake2), dim=1)\n",
    "    XX2 = torch.cat((eps * fake1 + (1 - eps) * fake1, eps * real + (1 - eps) * fake2), dim=1)\n",
    "    D1 = crit(XX1, t, batch_size)\n",
    "    D2 = crit(XX2, t, batch_size)\n",
    "    \n",
    "    '''\n",
    "    Gamma = torch.zeros_like(torch.empty(batch_size, 1))\n",
    "    for i in range(batch_size):\n",
    "        Gamma[i] = 1/2 * (torch.autograd.grad(D1[i,:], XX1[i,:])[0] + torch.autograd.grad(D2[i,:], XX2[i,:])[0])\n",
    "    '''\n",
    "    Gamma1 = torch.autograd.grad(\n",
    "        inputs=[XX1, t], \n",
    "        outputs=D1,\n",
    "        grad_outputs=torch.ones_like(D1),\n",
    "        create_graph=True,\n",
    "        retain_graph=True)[0]\n",
    "    Gamma2 = torch.autograd.grad(\n",
    "        inputs=[XX2, t], \n",
    "        outputs=D2,\n",
    "        grad_outputs=torch.ones_like(D2),\n",
    "        create_graph=True,\n",
    "        retain_graph=True)[0]\n",
    "    \n",
    "    Gamma = 1/2 * (Gamma1 + Gamma2)\n",
    "    \n",
    "    return torch.mean((torch.norm(Gamma, p=2) - 1) ** 2)\n",
    "\n",
    "def gl(models, data_loader, opt_gen, opt_crit, z_dim, mat_dim, n_critic=10):\n",
    "    \n",
    "    crit = models[0]\n",
    "    gen = models[1]\n",
    "    for batch_id, (real, rtarget) in enumerate(data_loader()):\n",
    "    \n",
    "    \n",
    "    \n",
    "        batch_size = real.shape[0]\n",
    "        #print('training data', real.shape, rtarget.shape)\n",
    "\n",
    "        real = real.view(-1, mat_dim ** 2).to(device)\n",
    "        rtarget = rtarget.view(-1, int(mat_dim ** 2 / 4)).to(device)\n",
    "        #print(real.shape, rtarget.shape)\n",
    "        #print(rtarget)\n",
    "\n",
    "        noise1 = torch.randn(batch_size, z_dim).to(device)\n",
    "        noise2 = torch.randn(batch_size, z_dim).to(device)\n",
    "        #print('1', noise1.shape)\n",
    "        noise1 = torch.cat((noise1, rtarget.view(batch_size,-1)), dim=1)\n",
    "        noise2 = torch.cat((noise2, rtarget.view(batch_size,-1)), dim=1)\n",
    "        #print('1', noise1.shape)\n",
    "\n",
    "        fake1 = gen(noise1)\n",
    "        fake2 = gen(noise2)\n",
    "\n",
    "        inp1 = torch.cat((real, fake1), dim=1)\n",
    "        inp2 = torch.cat((fake2, real), dim=1)\n",
    "        inp3 = torch.cat((fake1, fake2), dim=1)\n",
    "\n",
    "        crit1 = crit(inp1, rtarget, batch_size).view(-1)\n",
    "        crit2 = crit(inp2, rtarget, batch_size).view(-1)\n",
    "        crit3 = crit(inp3, rtarget, batch_size).view(-1)\n",
    "\n",
    "        L_G = loss_W(crit1, crit2, crit3) \n",
    "        gen.zero_grad()\n",
    "\n",
    "        L_G.backward()\n",
    "        opt_gen.step()\n",
    "        for _ in range(n_critic):\n",
    "            noise1 = torch.randn(batch_size, z_dim).to(device)\n",
    "            noise2 = torch.randn(batch_size, z_dim).to(device)\n",
    "\n",
    "            noise1 = torch.cat((noise1, rtarget.view(batch_size,-1)), dim=1).to(device)\n",
    "            noise2 = torch.cat((noise2, rtarget.view(batch_size,-1)), dim=1).to(device)\n",
    "\n",
    "            fake1 = gen(noise1)\n",
    "            fake2 = gen(noise2)\n",
    "\n",
    "            inp1 = torch.cat((real, fake1), dim=1)\n",
    "            inp2 = torch.cat((fake2, real), dim=1)\n",
    "            inp3 = torch.cat((fake1, fake2), dim=1)\n",
    "            inp4 = torch.cat((real, real), dim=1)\n",
    "\n",
    "            crit1 = crit(inp1, rtarget, batch_size).view(-1)\n",
    "            crit2 = crit(inp2, rtarget, batch_size).view(-1)\n",
    "            crit3 = crit(inp3, rtarget, batch_size).view(-1)\n",
    "            crit4 = crit(inp4, rtarget, batch_size).view(-1)\n",
    "            \n",
    "            a = loss_W(crit1, crit2, crit3)\n",
    "            b = loss_Drift(crit4)\n",
    "            c = loss_gp(fake1, fake2, real, rtarget, crit, batch_size)\n",
    "\n",
    "            L_D = (\n",
    "           -a + 1e-3 * b + 10 * c\n",
    "                )\n",
    "\n",
    "            crit.zero_grad()\n",
    "            L_D.backward(retain_graph=True)\n",
    "            opt_crit.step()\n",
    "            \n",
    "            \n",
    "    return L_D.item(), -a.item(), b.item(), c.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_eval(testing_ys, mat_dim, z_dim):\n",
    "    \n",
    "    loss_Ds, loss_Ws, loss_drifts, loss_gps = [], [], [], []\n",
    "\n",
    "\n",
    "    #models = create_SNF(4,256)\n",
    "    #4models\n",
    "    models = create_GAN(mat_dim, z_dim)\n",
    "    params  = []\n",
    "    for i in range(len(models)):\n",
    "        params += models[i].parameters()\n",
    "\n",
    "\n",
    "\n",
    "    #optimizer = Adam(params, lr = 1e-4)\n",
    "    #1e-4 0.185\n",
    "    #2e-4 0.2\n",
    "    #5e-5 0.17\n",
    "    #3e-5 0.18\n",
    "    #7e-5 0.22\n",
    "    #lr = 5e-5 wdist 15.7\n",
    "    lr = 1e-5\n",
    "    opt_crit = Adam(models[0].parameters(), lr=lr, betas=(0.5, 0.9), weight_decay=10e-4)\n",
    "    opt_gen = Adam(models[1].parameters(), lr=lr, betas=(0.5, 0.9), weight_decay=10e-4) \n",
    "\n",
    "\n",
    "\n",
    "    #700 0.16\n",
    "    #1000 0.149\n",
    "\n",
    "    num_epochs = 100#50#600#8\n",
    "    \n",
    "    batch_size = 64#128#64#\n",
    "    \n",
    "    num_samples_per_epoch = 2048#1024#6400\n",
    "\n",
    "    prog_bar = tqdm(total=num_epochs)\n",
    "    for i in range(num_epochs):\n",
    "        data_loader = get_epoch_data_loader_new(num_samples_per_epoch, batch_size, mat_dim)\n",
    "        loss_D, loss_W, loss_drift, loss_gp = gl(models, data_loader, opt_gen, opt_crit, z_dim, mat_dim)\n",
    "        loss_Ds += [loss_D]\n",
    "        loss_Ws += [loss_W]\n",
    "        loss_drifts += [loss_drift]\n",
    "        loss_gps += [loss_gp]\n",
    "        \n",
    "        #loss = train_inn_epoch(optimizer, models, params, b, data_loader, forward_map, mixture_params, convex_comb_factor=convex_comb_factor)\n",
    "\n",
    "        prog_bar.set_description('loss: {:.4f}'.format(loss_D))\n",
    "        prog_bar.update()\n",
    "    prog_bar.close()\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    return models, loss_Ds, loss_Ws, loss_drifts, loss_gps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(testing_ys, mat_dim, z_dim):\n",
    "    result = []\n",
    "    testing_x_per_y = 2048\n",
    "    weights1, weights2 = np.ones((testing_x_per_y,)) / testing_x_per_y, np.ones((testing_x_per_y,)) / testing_x_per_y\n",
    "\n",
    "    weights1 = weights1.astype(np.float64)\n",
    "    weights2 = weights2.astype(np.float64)\n",
    "    w1 = 0.\n",
    "\n",
    "    testing_num_y = len(testing_ys)\n",
    "    prog_bar = tqdm(total=testing_num_y)\n",
    "    prog_bar.set_description('Computing Wasserstein distances')\n",
    "    for i, y in enumerate(testing_ys):\n",
    "        #true_posterior_params = get_mixture_posterior(mixture_params, forward_map, b**2 * torch.eye(DIMENSION, device=device), y)\n",
    "        #true_posterior_samples = draw_mixture_dist(true_posterior_params, testing_x_per_y).cpu().numpy()\n",
    "        true_posterior_samples = draw_posterior_matrix(y, mat_dim, testing_x_per_y)\n",
    "        inflated_ys = y.flatten()[None, :].repeat(testing_x_per_y, 1)\n",
    "        #true_post = true_posterior_samples.reshape(-1, mat_dim, mat_dim)\n",
    "        true_post = true_posterior_samples.reshape(-1, mat_dim ** 2)\n",
    "        noise1 = torch.randn(testing_x_per_y, z_dim).to(device)\n",
    "        rtarget = inflated_ys\n",
    "        #testinp = torch.cat((noise1, rtarget.view(testing_x_per_y,-1)), dim=1)\n",
    "        testinp = torch.cat((noise1, rtarget.view(testing_x_per_y, -1)), dim=1)\n",
    "\n",
    "        samples1 = models[1](testinp).detach().cpu().numpy()\n",
    "        #print(y, samples1.shape)\n",
    "        #samples1 = samples1.reshape(testing_x_per_y, mat_dim,mat_dim)\n",
    "        samples1 = samples1.reshape(testing_x_per_y, mat_dim* mat_dim)\n",
    "        result += [samples1]\n",
    "        #print(np.round(samples1[0]))\n",
    "\n",
    "        #samples1 = forward_SNF(torch.randn(testing_x_per_y, DIMENSION, device=device), models, b, inflated_ys, mixture_params, forward_map)[0].detach().cpu().numpy()\n",
    "        \n",
    "        #samples2 = forward_SNF_det(torch.randn(testing_x_per_y, DIMENSION, device=device), models, b, inflated_ys, mixture_params, forward_map)[0].detach().cpu().numpy()\n",
    "        print(f'samples: {samples1.shape}, true: {true_post.shape}')\n",
    "        M1 = ot.dist(torch.tensor(samples1, dtype=torch.float32), true_post)\n",
    "\n",
    "        w1 += ot.emd2(weights1, weights2, M1)\n",
    "        prog_bar.set_description('W: {:.3f}'.format(w1 / (i + 1)))\n",
    "        prog_bar.update()\n",
    "    prog_bar.close()\n",
    "    print('Wasserstein:', w1 / testing_num_y)\n",
    "    return result\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_list = []\n",
    "\n",
    "testing_num_y = 100\n",
    "mat_dim = 8\n",
    "#mat_dim = 16\n",
    "z_dim = mat_dim\n",
    "#z_dim = 100\n",
    "\n",
    "#forward_map = create_forward_model(scale=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'forward keine id mehr scale=scale/i+1\\nmehr dimensionen\\nvgl inn\\nmixture parameter randomizen'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''forward keine id mehr scale=scale/i+1\n",
    "mehr dimensionen\n",
    "vgl inn\n",
    "mixture parameter randomizen'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing_xs = draw_x_mats(testing_num_y, mat_dim, z_dim)\n",
    "testing_xs = draw_x_mats(100, mat_dim)\n",
    "\n",
    "#print('testing x', testing_xs.shape)\n",
    "                \n",
    "testing_ys = forward_mat(testing_xs)\n",
    "#print(testing_xs.shape, testing_ys.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "loss: 0.0046:   0%|          | 0/100 [00:07<?, ?it/s]\u001b[A\n",
      "loss: 0.0046:   1%|          | 1/100 [00:07<12:37,  7.65s/it]\u001b[A\n",
      "loss: -0.0142:   1%|          | 1/100 [00:15<12:37,  7.65s/it]\u001b[A\n",
      "loss: -0.0142:   2%|▏         | 2/100 [00:15<12:38,  7.74s/it]\u001b[A\n",
      "loss: -0.0359:   2%|▏         | 2/100 [00:23<12:38,  7.74s/it]\u001b[A\n",
      "loss: -0.0359:   3%|▎         | 3/100 [00:23<12:35,  7.79s/it]\u001b[A\n",
      "loss: -0.0593:   3%|▎         | 3/100 [00:31<12:35,  7.79s/it]\u001b[A\n",
      "loss: -0.0593:   4%|▍         | 4/100 [00:31<12:25,  7.76s/it]\u001b[A\n",
      "loss: -0.0832:   4%|▍         | 4/100 [00:38<12:25,  7.76s/it]\u001b[A\n",
      "loss: -0.0832:   5%|▌         | 5/100 [00:38<12:17,  7.77s/it]\u001b[A\n",
      "loss: -0.1141:   5%|▌         | 5/100 [00:46<12:17,  7.77s/it]\u001b[A\n",
      "loss: -0.1141:   6%|▌         | 6/100 [00:46<12:09,  7.77s/it]\u001b[A\n",
      "loss: -0.1414:   6%|▌         | 6/100 [00:54<12:09,  7.77s/it]\u001b[A\n",
      "loss: -0.1414:   7%|▋         | 7/100 [00:54<12:10,  7.85s/it]\u001b[A\n",
      "loss: -0.1616:   7%|▋         | 7/100 [01:02<12:10,  7.85s/it]\u001b[A\n",
      "loss: -0.1616:   8%|▊         | 8/100 [01:02<12:01,  7.84s/it]\u001b[A\n",
      "loss: -0.1752:   8%|▊         | 8/100 [01:11<12:01,  7.84s/it]\u001b[A\n",
      "loss: -0.1752:   9%|▉         | 9/100 [01:11<12:17,  8.11s/it]\u001b[A\n",
      "loss: -0.1876:   9%|▉         | 9/100 [01:19<12:17,  8.11s/it]\u001b[A\n",
      "loss: -0.1876:  10%|█         | 10/100 [01:19<12:02,  8.03s/it]\u001b[A\n",
      "loss: -0.2046:  10%|█         | 10/100 [01:27<12:02,  8.03s/it]\u001b[A\n",
      "loss: -0.2046:  11%|█         | 11/100 [01:27<12:03,  8.12s/it]\u001b[A\n",
      "loss: -0.2173:  11%|█         | 11/100 [01:35<12:03,  8.12s/it]\u001b[A\n",
      "loss: -0.2173:  12%|█▏        | 12/100 [01:35<11:53,  8.11s/it]\u001b[A\n",
      "loss: -0.2261:  12%|█▏        | 12/100 [01:43<11:53,  8.11s/it]\u001b[A\n",
      "loss: -0.2261:  13%|█▎        | 13/100 [01:43<11:43,  8.09s/it]\u001b[A\n",
      "loss: -0.2379:  13%|█▎        | 13/100 [01:51<11:43,  8.09s/it]\u001b[A\n",
      "loss: -0.2379:  14%|█▍        | 14/100 [01:51<11:30,  8.03s/it]\u001b[A\n",
      "loss: -0.2499:  14%|█▍        | 14/100 [01:59<11:30,  8.03s/it]\u001b[A\n",
      "loss: -0.2499:  15%|█▌        | 15/100 [01:59<11:22,  8.02s/it]\u001b[A\n",
      "loss: -0.2704:  15%|█▌        | 15/100 [02:07<11:22,  8.02s/it]\u001b[A\n",
      "loss: -0.2704:  16%|█▌        | 16/100 [02:07<11:21,  8.11s/it]\u001b[A\n",
      "loss: -0.2705:  16%|█▌        | 16/100 [02:16<11:21,  8.11s/it]\u001b[A\n",
      "loss: -0.2705:  17%|█▋        | 17/100 [02:16<11:25,  8.26s/it]\u001b[A\n",
      "loss: -0.2875:  17%|█▋        | 17/100 [02:25<11:25,  8.26s/it]\u001b[A\n",
      "loss: -0.2875:  18%|█▊        | 18/100 [02:25<11:28,  8.40s/it]\u001b[A\n",
      "loss: -0.3017:  18%|█▊        | 18/100 [02:33<11:28,  8.40s/it]\u001b[A\n",
      "loss: -0.3017:  19%|█▉        | 19/100 [02:33<11:09,  8.27s/it]\u001b[A\n",
      "loss: -0.3206:  19%|█▉        | 19/100 [02:40<11:09,  8.27s/it]\u001b[A\n",
      "loss: -0.3206:  20%|██        | 20/100 [02:40<10:50,  8.13s/it]\u001b[A\n",
      "loss: -0.3345:  20%|██        | 20/100 [02:49<10:50,  8.13s/it]\u001b[A\n",
      "loss: -0.3345:  21%|██        | 21/100 [02:49<10:42,  8.13s/it]\u001b[A\n",
      "loss: -0.3457:  21%|██        | 21/100 [02:57<10:42,  8.13s/it]\u001b[A\n",
      "loss: -0.3457:  22%|██▏       | 22/100 [02:57<10:43,  8.25s/it]\u001b[A\n",
      "loss: -0.3590:  22%|██▏       | 22/100 [03:05<10:43,  8.25s/it]\u001b[A\n",
      "loss: -0.3590:  23%|██▎       | 23/100 [03:05<10:21,  8.07s/it]\u001b[A\n",
      "loss: -0.3804:  23%|██▎       | 23/100 [03:13<10:21,  8.07s/it]\u001b[A\n",
      "loss: -0.3804:  24%|██▍       | 24/100 [03:13<10:09,  8.02s/it]\u001b[A\n",
      "loss: -0.4024:  24%|██▍       | 24/100 [03:20<10:09,  8.02s/it]\u001b[A\n",
      "loss: -0.4024:  25%|██▌       | 25/100 [03:20<09:55,  7.94s/it]\u001b[A\n",
      "loss: -0.4092:  25%|██▌       | 25/100 [03:28<09:55,  7.94s/it]\u001b[A\n",
      "loss: -0.4092:  26%|██▌       | 26/100 [03:28<09:42,  7.87s/it]\u001b[A\n",
      "loss: -0.4182:  26%|██▌       | 26/100 [03:36<09:42,  7.87s/it]\u001b[A\n",
      "loss: -0.4182:  27%|██▋       | 27/100 [03:36<09:36,  7.90s/it]\u001b[A\n",
      "loss: -0.4442:  27%|██▋       | 27/100 [03:45<09:36,  7.90s/it]\u001b[A\n",
      "loss: -0.4442:  28%|██▊       | 28/100 [03:45<09:42,  8.09s/it]\u001b[A\n",
      "loss: -0.4478:  28%|██▊       | 28/100 [03:52<09:42,  8.09s/it]\u001b[A\n",
      "loss: -0.4478:  29%|██▉       | 29/100 [03:52<09:26,  7.98s/it]\u001b[A\n",
      "loss: -0.3904:  29%|██▉       | 29/100 [04:00<09:26,  7.98s/it]\u001b[A\n",
      "loss: -0.3904:  30%|███       | 30/100 [04:00<09:10,  7.86s/it]\u001b[A\n",
      "loss: -0.4612:  30%|███       | 30/100 [04:07<09:10,  7.86s/it]\u001b[A\n",
      "loss: -0.4612:  31%|███       | 31/100 [04:07<08:53,  7.73s/it]\u001b[A\n",
      "loss: -0.4540:  31%|███       | 31/100 [04:15<08:53,  7.73s/it]\u001b[A\n",
      "loss: -0.4540:  32%|███▏      | 32/100 [04:15<08:52,  7.83s/it]\u001b[A\n",
      "loss: -0.4740:  32%|███▏      | 32/100 [04:23<08:52,  7.83s/it]\u001b[A\n",
      "loss: -0.4740:  33%|███▎      | 33/100 [04:23<08:47,  7.87s/it]\u001b[A\n",
      "loss: -0.4732:  33%|███▎      | 33/100 [04:31<08:47,  7.87s/it]\u001b[A\n",
      "loss: -0.4732:  34%|███▍      | 34/100 [04:31<08:42,  7.92s/it]\u001b[A\n",
      "loss: -0.4593:  34%|███▍      | 34/100 [04:39<08:42,  7.92s/it]\u001b[A\n",
      "loss: -0.4593:  35%|███▌      | 35/100 [04:39<08:24,  7.76s/it]\u001b[A\n",
      "loss: -0.4822:  35%|███▌      | 35/100 [04:46<08:24,  7.76s/it]\u001b[A\n",
      "loss: -0.4822:  36%|███▌      | 36/100 [04:46<08:07,  7.62s/it]\u001b[A\n",
      "loss: -0.4780:  36%|███▌      | 36/100 [04:53<08:07,  7.62s/it]\u001b[A\n",
      "loss: -0.4780:  37%|███▋      | 37/100 [04:53<07:48,  7.44s/it]\u001b[A\n",
      "loss: -0.4960:  37%|███▋      | 37/100 [05:00<07:48,  7.44s/it]\u001b[A\n",
      "loss: -0.4960:  38%|███▊      | 38/100 [05:00<07:35,  7.35s/it]\u001b[A\n",
      "loss: -0.4971:  38%|███▊      | 38/100 [05:07<07:35,  7.35s/it]\u001b[A\n",
      "loss: -0.4971:  39%|███▉      | 39/100 [05:07<07:25,  7.30s/it]\u001b[A\n",
      "loss: -0.4870:  39%|███▉      | 39/100 [05:15<07:25,  7.30s/it]\u001b[A\n",
      "loss: -0.4870:  40%|████      | 40/100 [05:15<07:17,  7.29s/it]\u001b[A\n",
      "loss: -0.5018:  40%|████      | 40/100 [05:22<07:17,  7.29s/it]\u001b[A\n",
      "loss: -0.5018:  41%|████      | 41/100 [05:22<07:03,  7.17s/it]\u001b[A\n",
      "loss: -0.4992:  41%|████      | 41/100 [05:29<07:03,  7.17s/it]\u001b[A\n",
      "loss: -0.4992:  42%|████▏     | 42/100 [05:29<06:54,  7.15s/it]\u001b[A\n",
      "loss: -0.5068:  42%|████▏     | 42/100 [05:36<06:54,  7.15s/it]\u001b[A\n",
      "loss: -0.5068:  43%|████▎     | 43/100 [05:36<06:56,  7.30s/it]\u001b[A\n",
      "loss: -0.5009:  43%|████▎     | 43/100 [05:44<06:56,  7.30s/it]\u001b[A\n",
      "loss: -0.5009:  44%|████▍     | 44/100 [05:44<06:46,  7.26s/it]\u001b[A\n",
      "loss: -0.5080:  44%|████▍     | 44/100 [05:51<06:46,  7.26s/it]\u001b[A\n",
      "loss: -0.5080:  45%|████▌     | 45/100 [05:51<06:43,  7.34s/it]\u001b[A\n",
      "loss: 0.1551:  45%|████▌     | 45/100 [05:58<06:43,  7.34s/it] \u001b[A\n",
      "loss: 0.1551:  46%|████▌     | 46/100 [05:58<06:36,  7.34s/it]\u001b[A\n",
      "loss: -0.5059:  46%|████▌     | 46/100 [06:06<06:36,  7.34s/it]\u001b[A\n",
      "loss: -0.5059:  47%|████▋     | 47/100 [06:06<06:34,  7.44s/it]\u001b[A\n",
      "loss: -0.5104:  47%|████▋     | 47/100 [06:13<06:34,  7.44s/it]\u001b[A\n",
      "loss: -0.5104:  48%|████▊     | 48/100 [06:13<06:22,  7.35s/it]\u001b[A\n",
      "loss: -0.5150:  48%|████▊     | 48/100 [06:20<06:22,  7.35s/it]\u001b[A\n",
      "loss: -0.5150:  49%|████▉     | 49/100 [06:20<06:10,  7.26s/it]\u001b[A\n",
      "loss: -0.5037:  49%|████▉     | 49/100 [06:27<06:10,  7.26s/it]\u001b[A\n",
      "loss: -0.5037:  50%|█████     | 50/100 [06:27<05:57,  7.14s/it]\u001b[A\n",
      "loss: -0.5096:  50%|█████     | 50/100 [06:34<05:57,  7.14s/it]\u001b[A\n",
      "loss: -0.5096:  51%|█████     | 51/100 [06:34<05:48,  7.11s/it]\u001b[A\n",
      "loss: -0.5207:  51%|█████     | 51/100 [06:42<05:48,  7.11s/it]\u001b[A\n",
      "loss: -0.5207:  52%|█████▏    | 52/100 [06:42<05:47,  7.24s/it]\u001b[A\n",
      "loss: -0.5113:  52%|█████▏    | 52/100 [06:49<05:47,  7.24s/it]\u001b[A\n",
      "loss: -0.5113:  53%|█████▎    | 53/100 [06:49<05:47,  7.40s/it]\u001b[A\n",
      "loss: -0.5056:  53%|█████▎    | 53/100 [06:57<05:47,  7.40s/it]\u001b[A\n",
      "loss: -0.5056:  54%|█████▍    | 54/100 [06:57<05:35,  7.29s/it]\u001b[A\n",
      "loss: -0.5025:  54%|█████▍    | 54/100 [07:04<05:35,  7.29s/it]\u001b[A\n",
      "loss: -0.5025:  55%|█████▌    | 55/100 [07:04<05:27,  7.28s/it]\u001b[A\n",
      "loss: -0.5264:  55%|█████▌    | 55/100 [07:11<05:27,  7.28s/it]\u001b[A\n",
      "loss: -0.5264:  56%|█████▌    | 56/100 [07:11<05:19,  7.27s/it]\u001b[A\n",
      "loss: -0.5235:  56%|█████▌    | 56/100 [07:18<05:19,  7.27s/it]\u001b[A\n",
      "loss: -0.5235:  57%|█████▋    | 57/100 [07:18<05:13,  7.29s/it]\u001b[A\n",
      "loss: -0.5261:  57%|█████▋    | 57/100 [07:26<05:13,  7.29s/it]\u001b[A\n",
      "loss: -0.5261:  58%|█████▊    | 58/100 [07:26<05:11,  7.43s/it]\u001b[A\n",
      "loss: -0.5356:  58%|█████▊    | 58/100 [07:33<05:11,  7.43s/it]\u001b[A\n",
      "loss: -0.5356:  59%|█████▉    | 59/100 [07:33<04:57,  7.26s/it]\u001b[A\n",
      "loss: -0.5311:  59%|█████▉    | 59/100 [07:40<04:57,  7.26s/it]\u001b[A\n",
      "loss: -0.5311:  60%|██████    | 60/100 [07:40<04:44,  7.12s/it]\u001b[A\n",
      "loss: -0.0121:  60%|██████    | 60/100 [07:46<04:44,  7.12s/it]\u001b[A\n",
      "loss: -0.0121:  61%|██████    | 61/100 [07:46<04:33,  7.00s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: -0.2112:  61%|██████    | 61/100 [07:53<04:33,  7.00s/it]\u001b[A\n",
      "loss: -0.2112:  62%|██████▏   | 62/100 [07:53<04:21,  6.87s/it]\u001b[A\n",
      "loss: -0.5261:  62%|██████▏   | 62/100 [08:00<04:21,  6.87s/it]\u001b[A\n",
      "loss: -0.5261:  63%|██████▎   | 63/100 [08:00<04:16,  6.93s/it]\u001b[A\n",
      "loss: -0.5351:  63%|██████▎   | 63/100 [08:07<04:16,  6.93s/it]\u001b[A\n",
      "loss: -0.5351:  64%|██████▍   | 64/100 [08:07<04:12,  7.01s/it]\u001b[A\n",
      "loss: -0.5244:  64%|██████▍   | 64/100 [08:14<04:12,  7.01s/it]\u001b[A\n",
      "loss: -0.5244:  65%|██████▌   | 65/100 [08:14<04:05,  7.01s/it]\u001b[A\n",
      "loss: -0.5338:  65%|██████▌   | 65/100 [08:21<04:05,  7.01s/it]\u001b[A\n",
      "loss: -0.5338:  66%|██████▌   | 66/100 [08:21<03:58,  7.00s/it]\u001b[A\n",
      "loss: -0.3464:  66%|██████▌   | 66/100 [08:28<03:58,  7.00s/it]\u001b[A\n",
      "loss: -0.3464:  67%|██████▋   | 67/100 [08:28<03:52,  7.05s/it]\u001b[A\n",
      "loss: -0.5381:  67%|██████▋   | 67/100 [08:36<03:52,  7.05s/it]\u001b[A\n",
      "loss: -0.5381:  68%|██████▊   | 68/100 [08:36<03:50,  7.21s/it]\u001b[A\n",
      "loss: -0.5243:  68%|██████▊   | 68/100 [08:43<03:50,  7.21s/it]\u001b[A\n",
      "loss: -0.5243:  69%|██████▉   | 69/100 [08:43<03:43,  7.22s/it]\u001b[A\n",
      "loss: -0.5447:  69%|██████▉   | 69/100 [08:50<03:43,  7.22s/it]\u001b[A\n",
      "loss: -0.5447:  70%|███████   | 70/100 [08:50<03:34,  7.16s/it]\u001b[A\n",
      "loss: -0.5412:  70%|███████   | 70/100 [08:58<03:34,  7.16s/it]\u001b[A\n",
      "loss: -0.5412:  71%|███████   | 71/100 [08:58<03:28,  7.19s/it]\u001b[A\n",
      "loss: -0.5615:  71%|███████   | 71/100 [09:04<03:28,  7.19s/it]\u001b[A\n",
      "loss: -0.5615:  72%|███████▏  | 72/100 [09:04<03:18,  7.10s/it]\u001b[A\n",
      "loss: -0.5544:  72%|███████▏  | 72/100 [09:11<03:18,  7.10s/it]\u001b[A\n",
      "loss: -0.5544:  73%|███████▎  | 73/100 [09:11<03:10,  7.06s/it]\u001b[A\n",
      "loss: -0.5401:  73%|███████▎  | 73/100 [09:18<03:10,  7.06s/it]\u001b[A\n",
      "loss: -0.5401:  74%|███████▍  | 74/100 [09:18<03:02,  7.01s/it]\u001b[A\n",
      "loss: -0.5532:  74%|███████▍  | 74/100 [09:25<03:02,  7.01s/it]\u001b[A\n",
      "loss: -0.5532:  75%|███████▌  | 75/100 [09:25<02:54,  6.98s/it]\u001b[A\n",
      "loss: -0.5642:  75%|███████▌  | 75/100 [09:32<02:54,  6.98s/it]\u001b[A\n",
      "loss: -0.5642:  76%|███████▌  | 76/100 [09:32<02:47,  6.96s/it]\u001b[A\n",
      "loss: -0.5547:  76%|███████▌  | 76/100 [09:39<02:47,  6.96s/it]\u001b[A\n",
      "loss: -0.5547:  77%|███████▋  | 77/100 [09:39<02:40,  6.96s/it]\u001b[A\n",
      "loss: -0.5665:  77%|███████▋  | 77/100 [09:47<02:40,  6.96s/it]\u001b[A\n",
      "loss: -0.5665:  78%|███████▊  | 78/100 [09:47<02:38,  7.18s/it]\u001b[A\n",
      "loss: -0.3465:  78%|███████▊  | 78/100 [09:54<02:38,  7.18s/it]\u001b[A\n",
      "loss: -0.3465:  79%|███████▉  | 79/100 [09:54<02:33,  7.31s/it]\u001b[A\n",
      "loss: -0.5665:  79%|███████▉  | 79/100 [10:01<02:33,  7.31s/it]\u001b[A\n",
      "loss: -0.5665:  80%|████████  | 80/100 [10:01<02:24,  7.21s/it]\u001b[A\n",
      "loss: -0.5698:  80%|████████  | 80/100 [10:08<02:24,  7.21s/it]\u001b[A\n",
      "loss: -0.5698:  81%|████████  | 81/100 [10:08<02:15,  7.14s/it]\u001b[A\n",
      "loss: 0.0939:  81%|████████  | 81/100 [10:16<02:15,  7.14s/it] \u001b[A\n",
      "loss: 0.0939:  82%|████████▏ | 82/100 [10:16<02:09,  7.18s/it]\u001b[A\n",
      "loss: -0.5565:  82%|████████▏ | 82/100 [10:23<02:09,  7.18s/it]\u001b[A\n",
      "loss: -0.5565:  83%|████████▎ | 83/100 [10:23<02:02,  7.19s/it]\u001b[A\n",
      "loss: -0.5588:  83%|████████▎ | 83/100 [10:30<02:02,  7.19s/it]\u001b[A\n",
      "loss: -0.5588:  84%|████████▍ | 84/100 [10:30<01:54,  7.15s/it]\u001b[A\n",
      "loss: -0.5568:  84%|████████▍ | 84/100 [10:37<01:54,  7.15s/it]\u001b[A\n",
      "loss: -0.5568:  85%|████████▌ | 85/100 [10:37<01:47,  7.16s/it]\u001b[A\n",
      "loss: -0.5704:  85%|████████▌ | 85/100 [10:44<01:47,  7.16s/it]\u001b[A\n",
      "loss: -0.5704:  86%|████████▌ | 86/100 [10:44<01:40,  7.21s/it]\u001b[A\n",
      "loss: -0.5866:  86%|████████▌ | 86/100 [10:52<01:40,  7.21s/it]\u001b[A\n",
      "loss: -0.5866:  87%|████████▋ | 87/100 [10:52<01:35,  7.38s/it]\u001b[A\n",
      "loss: 0.3489:  87%|████████▋ | 87/100 [11:01<01:35,  7.38s/it] \u001b[A\n",
      "loss: 0.3489:  88%|████████▊ | 88/100 [11:01<01:32,  7.75s/it]\u001b[A\n",
      "loss: -0.5834:  88%|████████▊ | 88/100 [11:09<01:32,  7.75s/it]\u001b[A\n",
      "loss: -0.5834:  89%|████████▉ | 89/100 [11:09<01:25,  7.73s/it]\u001b[A\n",
      "loss: -0.5858:  89%|████████▉ | 89/100 [11:16<01:25,  7.73s/it]\u001b[A\n",
      "loss: -0.5858:  90%|█████████ | 90/100 [11:16<01:15,  7.57s/it]\u001b[A\n",
      "loss: 1.3000:  90%|█████████ | 90/100 [11:23<01:15,  7.57s/it] \u001b[A\n",
      "loss: 1.3000:  91%|█████████ | 91/100 [11:23<01:07,  7.45s/it]\u001b[A\n",
      "loss: -0.5809:  91%|█████████ | 91/100 [11:30<01:07,  7.45s/it]\u001b[A\n",
      "loss: -0.5809:  92%|█████████▏| 92/100 [11:30<00:58,  7.35s/it]\u001b[A\n",
      "loss: -0.5755:  92%|█████████▏| 92/100 [11:37<00:58,  7.35s/it]\u001b[A\n",
      "loss: -0.5755:  93%|█████████▎| 93/100 [11:37<00:51,  7.31s/it]\u001b[A\n",
      "loss: -0.5864:  93%|█████████▎| 93/100 [11:44<00:51,  7.31s/it]\u001b[A\n",
      "loss: -0.5864:  94%|█████████▍| 94/100 [11:44<00:43,  7.25s/it]\u001b[A\n",
      "loss: -0.5911:  94%|█████████▍| 94/100 [11:52<00:43,  7.25s/it]\u001b[A\n",
      "loss: -0.5911:  95%|█████████▌| 95/100 [11:52<00:36,  7.24s/it]\u001b[A\n",
      "loss: -0.5893:  95%|█████████▌| 95/100 [11:59<00:36,  7.24s/it]\u001b[A\n",
      "loss: -0.5893:  96%|█████████▌| 96/100 [11:59<00:29,  7.27s/it]\u001b[A\n",
      "loss: -0.5969:  96%|█████████▌| 96/100 [12:06<00:29,  7.27s/it]\u001b[A\n",
      "loss: -0.5969:  97%|█████████▋| 97/100 [12:06<00:21,  7.19s/it]\u001b[A\n",
      "loss: -0.5050:  97%|█████████▋| 97/100 [12:13<00:21,  7.19s/it]\u001b[A\n",
      "loss: -0.5050:  98%|█████████▊| 98/100 [12:13<00:14,  7.16s/it]\u001b[A\n",
      "loss: -0.5837:  98%|█████████▊| 98/100 [12:20<00:14,  7.16s/it]\u001b[A\n",
      "loss: -0.5837:  99%|█████████▉| 99/100 [12:20<00:07,  7.22s/it]\u001b[A\n",
      "loss: -0.5985:  99%|█████████▉| 99/100 [12:29<00:07,  7.22s/it]\u001b[A\n",
      "loss: -0.5985: 100%|██████████| 100/100 [12:29<00:00,  7.49s/it]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "\n",
    "models, loss_Ds, loss_Ws, loss_drifts, loss_gps = train_and_eval(testing_ys, mat_dim, z_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Wasserstein distances:   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 8, 8]) torch.Size([100, 4, 4])\n",
      "4\n",
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 13.918:   1%|          | 1/100 [00:02<03:28,  2.11s/it]              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.756:   2%|▏         | 2/100 [00:04<03:27,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.963:   3%|▎         | 3/100 [00:06<03:24,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.938:   4%|▍         | 4/100 [00:08<03:20,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.771:   5%|▌         | 5/100 [00:10<03:18,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.712:   6%|▌         | 6/100 [00:12<03:15,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.774:   7%|▋         | 7/100 [00:14<03:11,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.569:   8%|▊         | 8/100 [00:16<03:06,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.561:   9%|▉         | 9/100 [00:18<03:06,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.766:  10%|█         | 10/100 [00:20<03:03,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.729:  11%|█         | 11/100 [00:22<03:02,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.706:  12%|█▏        | 12/100 [00:24<03:01,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.659:  13%|█▎        | 13/100 [00:26<02:59,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.765:  14%|█▍        | 14/100 [00:28<02:58,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.774:  15%|█▌        | 15/100 [00:31<02:57,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.907:  16%|█▌        | 16/100 [00:33<02:57,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.885:  17%|█▋        | 17/100 [00:35<02:54,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.890:  18%|█▊        | 18/100 [00:37<02:50,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.879:  19%|█▉        | 19/100 [00:39<02:51,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.830:  20%|██        | 20/100 [00:41<02:49,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.770:  21%|██        | 21/100 [00:43<02:44,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.711:  22%|██▏       | 22/100 [00:45<02:40,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.718:  23%|██▎       | 23/100 [00:47<02:39,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.688:  24%|██▍       | 24/100 [00:49<02:36,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.678:  25%|██▌       | 25/100 [00:51<02:33,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.672:  26%|██▌       | 26/100 [00:53<02:31,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.712:  27%|██▋       | 27/100 [00:56<02:32,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.714:  28%|██▊       | 28/100 [00:58<02:30,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.715:  29%|██▉       | 29/100 [01:00<02:27,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.705:  30%|███       | 30/100 [01:02<02:23,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.702:  31%|███       | 31/100 [01:04<02:20,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.697:  32%|███▏      | 32/100 [01:06<02:19,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.694:  33%|███▎      | 33/100 [01:08<02:18,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.643:  34%|███▍      | 34/100 [01:10<02:15,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.667:  35%|███▌      | 35/100 [01:12<02:15,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.704:  36%|███▌      | 36/100 [01:14<02:13,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.702:  37%|███▋      | 37/100 [01:16<02:11,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.754:  38%|███▊      | 38/100 [01:18<02:10,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.706:  39%|███▉      | 39/100 [01:20<02:07,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.748:  40%|████      | 40/100 [01:23<02:05,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.726:  41%|████      | 41/100 [01:25<02:02,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.722:  42%|████▏     | 42/100 [01:27<01:59,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.736:  43%|████▎     | 43/100 [01:29<01:57,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.720:  44%|████▍     | 44/100 [01:31<01:55,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.685:  45%|████▌     | 45/100 [01:33<01:53,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.643:  46%|████▌     | 46/100 [01:35<01:50,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.641:  47%|████▋     | 47/100 [01:37<01:48,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.625:  48%|████▊     | 48/100 [01:39<01:46,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.642:  49%|████▉     | 49/100 [01:41<01:43,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.631:  50%|█████     | 50/100 [01:43<01:41,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.625:  51%|█████     | 51/100 [01:45<01:38,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.671:  52%|█████▏    | 52/100 [01:47<01:38,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.700:  53%|█████▎    | 53/100 [01:49<01:36,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.704:  54%|█████▍    | 54/100 [01:51<01:33,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.735:  55%|█████▌    | 55/100 [01:53<01:33,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.700:  56%|█████▌    | 56/100 [01:55<01:30,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.697:  57%|█████▋    | 57/100 [01:57<01:28,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.697:  58%|█████▊    | 58/100 [02:00<01:27,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.686:  59%|█████▉    | 59/100 [02:01<01:24,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.706:  60%|██████    | 60/100 [02:04<01:22,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.696:  61%|██████    | 61/100 [02:06<01:19,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.720:  62%|██████▏   | 62/100 [02:08<01:18,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.696:  63%|██████▎   | 63/100 [02:10<01:16,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.699:  64%|██████▍   | 64/100 [02:12<01:13,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.684:  65%|██████▌   | 65/100 [02:14<01:11,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.657:  66%|██████▌   | 66/100 [02:16<01:10,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.649:  67%|██████▋   | 67/100 [02:18<01:07,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.642:  68%|██████▊   | 68/100 [02:20<01:05,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.639:  69%|██████▉   | 69/100 [02:22<01:03,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.590:  70%|███████   | 70/100 [02:24<01:00,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.577:  71%|███████   | 71/100 [02:26<00:59,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.597:  72%|███████▏  | 72/100 [02:28<00:58,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.592:  73%|███████▎  | 73/100 [02:30<00:56,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.613:  74%|███████▍  | 74/100 [02:32<00:54,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.603:  75%|███████▌  | 75/100 [02:35<00:52,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.636:  76%|███████▌  | 76/100 [02:37<00:50,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.652:  77%|███████▋  | 77/100 [02:39<00:48,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.656:  78%|███████▊  | 78/100 [02:41<00:45,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.674:  79%|███████▉  | 79/100 [02:43<00:43,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.690:  80%|████████  | 80/100 [02:45<00:42,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.683:  81%|████████  | 81/100 [02:47<00:40,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.655:  82%|████████▏ | 82/100 [02:49<00:38,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.664:  83%|████████▎ | 83/100 [02:51<00:35,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.677:  84%|████████▍ | 84/100 [02:54<00:33,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.701:  85%|████████▌ | 85/100 [02:56<00:31,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.704:  86%|████████▌ | 86/100 [02:58<00:29,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.710:  87%|████████▋ | 87/100 [03:00<00:27,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.686:  88%|████████▊ | 88/100 [03:02<00:24,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.689:  89%|████████▉ | 89/100 [03:04<00:22,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.696:  90%|█████████ | 90/100 [03:06<00:20,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.691:  91%|█████████ | 91/100 [03:08<00:18,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.695:  92%|█████████▏| 92/100 [03:10<00:16,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.716:  93%|█████████▎| 93/100 [03:12<00:14,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.724:  94%|█████████▍| 94/100 [03:14<00:12,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.709:  95%|█████████▌| 95/100 [03:16<00:10,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.672:  96%|█████████▌| 96/100 [03:19<00:08,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.668:  97%|█████████▋| 97/100 [03:21<00:06,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.688:  98%|█████████▊| 98/100 [03:23<00:04,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.681:  99%|█████████▉| 99/100 [03:25<00:02,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: (2048, 64), true: torch.Size([2048, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W: 14.688: 100%|██████████| 100/100 [03:27<00:00,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wasserstein: 14.68767139754258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(testing_xs.shape, testing_ys.shape)\n",
    "print(len(split(testing_ys[0], mat_dim)))\n",
    "result = eval(testing_ys, mat_dim, z_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2048, 64)\n",
      "0.28484106\n"
     ]
    }
   ],
   "source": [
    "print(result[0].shape)\n",
    "mse = []\n",
    "for i in range(result[0].shape[0]):\n",
    "    mse += [((np.array(testing_xs[1]) - np.array(result[1][i].reshape(8,8)))**2).mean(axis=None)]\n",
    "print(np.array(mse).mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'W-dist WGAN: 15.54, INN: 15.81'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''W-dist WGAN: 15.54, INN: 15.81'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Critic_multin_big(\n",
       "   (crit): Sequential(\n",
       "     (0): Linear(in_features=144, out_features=256, bias=True)\n",
       "     (1): LeakyReLU(negative_slope=0.1)\n",
       "     (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (3): LeakyReLU(negative_slope=0.1)\n",
       "     (4): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (5): LeakyReLU(negative_slope=0.1)\n",
       "     (6): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (7): LeakyReLU(negative_slope=0.05)\n",
       "     (8): Linear(in_features=256, out_features=1, bias=True)\n",
       "   )\n",
       " ),\n",
       " Generator_big(\n",
       "   (gen): Sequential(\n",
       "     (0): Linear(in_features=24, out_features=256, bias=True)\n",
       "     (1): LeakyReLU(negative_slope=0.1)\n",
       "     (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (3): LeakyReLU(negative_slope=0.1)\n",
       "     (4): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (5): LeakyReLU(negative_slope=0.1)\n",
       "     (6): Linear(in_features=256, out_features=64, bias=True)\n",
       "     (7): Sigmoid()\n",
       "   )\n",
       " ))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "print(np.array(mse).mean())\n",
    "print(preprocessing.normalize(result[0][4]))\n",
    "print(testing_xs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-f564ee5e58c5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mforward_mat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmat_dim\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmat_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtesting_ys\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mtesting_ys\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtesting_xs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'result' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "test = forward_mat(torch.round(torch.tensor(result[0][20], dtype=torch.float32).reshape(1,mat_dim,mat_dim)))\n",
    "print(test)\n",
    "print(testing_ys[0])\n",
    "print(test == testing_ys[0])\n",
    "print(testing_xs[0])\n",
    "print(torch.round(torch.tensor(result[0][20], dtype=torch.float32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "torch.save(models[1].state_dict(), r'C:\\Users\\Karl\\TUB\\Master Thesis\\gen_mat_13W.pt')\n",
    "torch.save(models[0].state_dict(), r'C:\\Users\\Karl\\TUB\\Master Thesis\\crit_mat_13W.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''crit, gen = create_GAN(mat_dim, mat_dim)\n",
    "crit.load_state_dict(torch.load(r'C:\\Users\\Karl\\TUB\\Master Thesis\\crit_mat.pt'))\n",
    "crit.eval()\n",
    "gen.load_state_dict(torch.load(r'C:\\Users\\Karl\\TUB\\Master Thesis\\gen_mat.pt'))\n",
    "gen.eval()\n",
    "models = (crit, gen)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-87-0536a18a3ed9>:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  C = forward_mat(torch.tensor(A, dtype=torch.float32).reshape(1,16,16)).reshape(8,8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x280e9c71bb0>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "l = 16 * [1]\n",
    "A = torch.tensor([[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n",
    "                 [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n",
    "                 [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n",
    "                 [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n",
    "                 [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n",
    "                 [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n",
    "                 [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n",
    "                 [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n",
    "                  l,l,l,l,l,l,l,l\n",
    "]) \n",
    "C = forward_mat(torch.tensor(A, dtype=torch.float32).reshape(1,16,16)).reshape(8,8)\n",
    "plt.figure()\n",
    "plt.imshow(A, cmap=plt.cm.gray)\n",
    "plt.figure()\n",
    "plt.imshow(C, cmap=plt.cm.gray)\n",
    "noise1 = torch.randn(1, z_dim)\n",
    "noise = torch.cat((noise1, C.view(1,-1)), dim=1)\n",
    "\n",
    "gen = test(noise)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(gen.detach().numpy().reshape(16,16), cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-108-7dc0259a4042>:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  C = forward_mat(torch.tensor(A, dtype=torch.float32).reshape(1,8,8)).reshape(4,4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x280e9c6a4c0>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPUAAAD4CAYAAAA0L6C7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAMLklEQVR4nO3dX4hc9RnG8efpZrPWRiNZbTSJaECJSE01BEEsYhVFq9heFDSgUCmIF4rSgqjgRfFe7EUVQ9QKWrX1DwRJtaIbUqFGzZ+2mkTRJSWJ0Wiq+bPirsa3FzuR1WzcM7Pn/Gby9vuBJTNzDud9J9kn58yZc34/R4QA5PG9bjcAoF6EGkiGUAPJEGogGUINJDOjiY3Onj075s6d28SmDzE2NlakjiTNmNHIX9dh7d27t1ito446KmUt28VqSdLo6GiROrt379a+ffsmfXON/JbOnTtX9913XxObPsTWrVuL1JGkwcHBYrUk6aWXXipWa9GiRcVqnXHGGcVq9ff3F6slSe+9916ROnffffdhl3H4DSRDqIFkCDWQDKEGkiHUQDKEGkiGUAPJEGogGUINJFMp1LYvs/227Xdt3950UwA6N2WobfdJ+oOkyyWdKWmZ7TObbgxAZ6rsqc+V9G5EDEfEmKQnJP282bYAdKpKqOdL2jbh+fbWa99g+wbbb9h+Y8+ePXX1B6BNtZ0oi4jlEbE0IpbOnj27rs0CaFOVUO+QdPKE5wtarwHoQVVC/bqk020vtD1T0jWSVjbbFoBOTTlIQkR8afsmSS9I6pP0UES81XhnADpSaeSTiFglaVXDvQCoAVeUAckQaiAZQg0kQ6iBZAg1kAyhBpIh1EAyjczQMTo6qnfeeaeJTR9iZGSkSB1JevLJJ4vVkqR58+YVq/Xaa68VqzVz5sxitUpOXSRJw8PDRep89tlnh13GnhpIhlADyRBqIBlCDSRDqIFkCDWQDKEGkiHUQDKEGkiGUAPJVJmh4yHbu2y/WaIhANNTZU/9R0mXNdwHgJpMGeqIWCPpvwV6AVCD2j5TT5x2Z//+/XVtFkCbGpl2Z9asWXVtFkCbOPsNJEOogWSqfKX1uKR/SFpke7vtXzffFoBOVZlLa1mJRgDUg8NvIBlCDSRDqIFkCDWQDKEGkiHUQDKEGkjGEVH7RhcvXhwrV66sfbuTWbduXZE6ktTf31+slvTdU6vU7ZRTTilWa2hoqFit+fPnF6slSQMDA0Xq3HnnnRoeHvZky9hTA8kQaiAZQg0kQ6iBZAg1kAyhBpIh1EAyhBpIhlADyRBqIJkqY5SdbHvI9ibbb9m+pURjADoz5Rhlkr6U9NuIWG/7GEnrbL8YEZsa7g1AB6pMu7MzIta3Hu+TtFlS2avkAVTW1mdq26dKOkfS2kmWfT3tzu7du2tqD0C7Kofa9ixJT0u6NSL2fnv5xGl3BgcH6+wRQBsqhdp2v8YD/VhEPNNsSwCmo8rZb0t6UNLmiLin+ZYATEeVPfX5kq6TdJHtja2fnzXcF4AOVZl25xVJkw6bAqD3cEUZkAyhBpIh1EAyhBpIhlADyRBqIBlCDSRDqIFkqtxP3baRkRGtXXvIjVyNuPrqq4vUkaS77rqrWC1JWrZsWbFaO3fuLFZryZIlxWrNmjWrWC1J2rv3kHudGtHX13fYZeypgWQINZAMoQaSIdRAMoQaSIZQA8kQaiAZQg0kQ6iBZKoMPHiU7dds/7M17c7vSjQGoDNVLhMdlXRRROxvDRX8iu2/RsSrDfcGoANVBh4MSftbT/tbP9FkUwA6V3Uw/z7bGyXtkvRiRHzntDulLmoHcKhKoY6IAxFxtqQFks61/aNJ1vl62p1jjz225jYBVNXW2e+I+FTSkKTLGukGwLRVOft9gu3jWo+/L+kSSVsa7gtAh6qc/T5J0iO2+zT+n8CfI+K5ZtsC0KkqZ7//pfE5qQEcAbiiDEiGUAPJEGogGUINJEOogWQINZAMoQaSIdRAMh6/s7Jec+bMiUsvvbT27U5mYGCgSB1JGhwcLFZLkrZu3Vqs1v79+6deqSYbNmwoVqvk1EWStG3btiJ1Vq9erU8++cSTLWNPDSRDqIFkCDWQDKEGkiHUQDKEGkiGUAPJEGogGUINJEOogWQqh7o1oP8G2ww6CPSwdvbUt0ja3FQjAOpRddqdBZKukLSi2XYATFfVPfW9km6T9NXhVpg4l9bo6GgdvQHoQJUZOq6UtCsi1n3XehPn0ip5OySAb6qypz5f0lW2t0p6QtJFth9ttCsAHZsy1BFxR0QsiIhTJV0j6eWIuLbxzgB0hO+pgWSqTJD3tYhYLWl1I50AqAV7aiAZQg0kQ6iBZAg1kAyhBpIh1EAyhBpIppFpdwYGBuLEE0+sfbuTmTNnTpE6krRw4cJitSRpeHi4WK2Sf49btmwpVquJ3+/vcuONNxap88ADD+j9999n2h3g/wGhBpIh1EAyhBpIhlADyRBqIBlCDSRDqIFkCDWQDKEGkqk0nFFrJNF9kg5I+jIiljbZFIDOtTNG2U8j4uPGOgFQCw6/gWSqhjok/c32Ots3TLbCxGl3Dhw4UF+HANpS9fD7JxGxw/YPJb1oe0tErJm4QkQsl7RcGr/1suY+AVRUaU8dETtaf+6S9Kykc5tsCkDnqkyQ9wPbxxx8LOlSSW823RiAzlQ5/J4r6VnbB9f/U0Q832hXADo2ZagjYljSjwv0AqAGfKUFJEOogWQINZAMoQaSIdRAMoQaSIZQA8m0c+tlZf39/Zo3b14Tmz7EWWedVaSOJA0NDRWrJUnHH398sVpjY2PFai1evLhYrTVr1ky9Uo1WrVpVpM6ePXsOu4w9NZAMoQaSIdRAMoQaSIZQA8kQaiAZQg0kQ6iBZAg1kAyhBpKpFGrbx9l+yvYW25ttn9d0YwA6U/Xa799Lej4ifml7pqSjG+wJwDRMGWrbsyVdIOlXkhQRY5LKXf0PoC1VDr8XSvpI0sO2N9he0Rr/+xsmTrvzxRdf1N4ogGqqhHqGpCWS7o+IcySNSLr92ytFxPKIWBoRS/v7+2tuE0BVVUK9XdL2iFjbev6UxkMOoAdNGeqI+EDSNtuLWi9dLGlTo10B6FjVs983S3qsdeZ7WNL1zbUEYDoqhToiNkpa2mwrAOrAFWVAMoQaSIZQA8kQaiAZQg0kQ6iBZAg1kAyhBpJpZC6tkZERvfrqq01s+hCff/55kTqSis0PdtCFF15YrNbatWunXqkmp512WrFaH374YbFakjQ4OFikzowZh48ue2ogGUINJEOogWQINZAMoQaSIdRAMoQaSIZQA8kQaiCZKUNte5HtjRN+9tq+tUBvADow5WWiEfG2pLMlyXafpB2Snm22LQCdavfw+2JJ70XEf5poBsD0tXtDxzWSHp9sge0bJN0w7Y4ATEvlPXVrzO+rJP1lsuUTp92pqzkA7Wvn8PtySesjouy9bADa0k6ol+kwh94AekelULemrr1E0jPNtgNguqpOuzMiqcyQDgCmhSvKgGQINZAMoQaSIdRAMoQaSIZQA8kQaiAZQg0k44iof6P2R5LavT3zeEkf195Mb8j63nhf3XNKRJww2YJGQt0J229kvcMr63vjffUmDr+BZAg1kEwvhXp5txtoUNb3xvvqQT3zmRpAPXppTw2gBoQaSKYnQm37Mttv237X9u3d7qcOtk+2PWR7k+23bN/S7Z7qZLvP9gbbz3W7lzrZPs72U7a32N5s+7xu99Surn+mbk0Q8I7Gh0vaLul1ScsiYlNXG5sm2ydJOiki1ts+RtI6Sb840t/XQbZ/I2mppGMj4spu91MX249I+ntErGiNoHt0RHza5bba0gt76nMlvRsRwxExJukJST/vck/TFhE7I2J96/E+SZslze9uV/WwvUDSFZJWdLuXOtmeLekCSQ9KUkSMHWmBlnoj1PMlbZvwfLuS/PIfZPtUSedIWtvlVupyr6TbJH3V5T7qtlDSR5Iebn20WNEadPOI0guhTs32LElPS7o1IvZ2u5/psn2lpF0Rsa7bvTRghqQlku6PiHMkjUg64s7x9EKod0g6ecLzBa3Xjni2+zUe6MciIsvwyudLusr2Vo1/VLrI9qPdbak22yVtj4iDR1RPaTzkR5ReCPXrkk63vbB1YuIaSSu73NO02bbGP5ttjoh7ut1PXSLijohYEBGnavzf6uWIuLbLbdUiIj6QtM32otZLF0s64k5stjtBXu0i4kvbN0l6QVKfpIci4q0ut1WH8yVdJ+nftje2XrszIlZ1ryVUcLOkx1o7mGFJ13e5n7Z1/SstAPXqhcNvADUi1EAyhBpIhlADyRBqIBlCDSRDqIFk/gc4VfaqKGIhrAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "A = np.round(np.random.random((8,8)))\n",
    "z = 8 * [0]\n",
    "o = 8 * [1]\n",
    "A = torch.tensor([o,o,o,o,z,z,z,z])\n",
    "C = forward_mat(torch.tensor(A, dtype=torch.float32).reshape(1,8,8)).reshape(4,4)\n",
    "plt.figure()\n",
    "plt.imshow(A, cmap=plt.cm.gray)\n",
    "plt.figure()\n",
    "plt.imshow(C, cmap=plt.cm.gray)\n",
    "noise1 = torch.randn(1, z_dim)\n",
    "noise = torch.cat((noise1, C.view(1,-1)), dim=1)\n",
    "test = models[1].eval()\n",
    "gen = test(noise)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(gen.detach().numpy().reshape(8,8), cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 16, 16]) torch.Size([64, 8, 8])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD4CAYAAAAjDTByAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAS9ElEQVR4nO3df5BV5X3H8fc3wMIKBFytRASFYCZqFZEgkZDEpFoEGwVj/tA0BZNMMk4bmnTSZEjN1Ez/yCRNSVrbJMYaK7UOaGNs0CCBJjraiaAE+b0iCAuCLFhR1oWY3YVv/7iHzGXdC/d57jkH7PN5zezs3Xuf7z5fzt0P595z77mPuTsikp53nOwGROTkUPhFEqXwiyRK4RdJlMIvkqj+ZU7W1NTkzc3NwXUDBw4Mrjl48GBwDcDgwYODa7q7u6Pmin2lZdCgQcE1PT09UXMNHTo0qi5Gmdvx8OHDUXMdOXIkqi7m776rqyu45sCBAxw6dMjqGVtq+Jubm5k6dWpw3bhx44JrVqxYEVwDcMUVVwTX7NmzJ2qu2D/2Cy64ILhm3759UXN99KMfjaqLCUnsdowJckdHR9RcnZ2dUXXjx48PrmlrawuuWbBgQd1j9bBfJFEKv0iiGgq/mU03s81mttXM5uXVlIgULzr8ZtYP+D4wA7gIuNnMLsqrMREpViN7/snAVnff5u5dwCJgZj5tiUjRGgn/OcBLVT/vyq47hpl93sxWmdmqmJcuRKQYhR/wc/e73H2Su09qamoqejoRqVMj4d8NjK76eVR2nYi8DTQS/meB95jZWDNrAm4CFufTlogULfodfu7eY2ZfAH4B9APucfeNuXUmIoVq6O297r4EWJJTLyJSIr3DTyRRpZ7YM3z4cK6//vrgugceeCC4JubsPIBnn302uOaWW26JmuvJJ5+Mqos5sSfm3wXQ2toaVXfNNdcE15x//vlRcz366KPBNVu3bo2aa8KECVF1+/fvD65ZunRpcM2BAwfqHqs9v0iiFH6RRCn8IolS+EUSpfCLJErhF0mUwi+SKIVfJFEKv0iiFH6RRCn8IolS+EUSVeqJPV1dXezcuTO47pJLLgmuGTt2bHANwO9+97vgmkOHDkXNdfnll0fV3XfffcE15513XtRcMSvNADz44IPBNS+//HLUXDGrLMXUAFF/vwC33XZbcE17e3twTciqR9rziyRK4RdJlMIvkqhGVuwZbWaPm9kmM9toZl/MszERKVYjB/x6gC+7+2ozGwr8xsyWu/umnHoTkQJF7/ndfY+7r84uvwG00seKPSJyasrlOb+ZjQEuA1b2cdvvl+uKfUlMRPLXcPjNbAjwEPAld+/ofXv1cl2nnXZao9OJSE4aCr+ZDaAS/Pvd/af5tCQiZWjkaL8BPwZa3f27+bUkImVoZM8/Ffgz4I/MbE32dW1OfYlIwRpZq+9/AMuxFxEpkd7hJ5Ko0s/q27VrV5lTBlu3bl1wTVdXV9RcR44ciaq74YYbgmvWrl0bNdfGjXELL1933XXBNU1NTVFzff3rXw+umTp1atRc/fr1i6r73Oc+F1wzbdq04JqBAwfWPVZ7fpFEKfwiiVL4RRKl8IskSuEXSZTCL5IohV8kUQq/SKIUfpFEKfwiiVL4RRKl8IskqtQTewYPHszkyZOD6+69997gmtiPDOvp6Qmu2b59e9Rcc+fOjarr7u4OroldCuud73xnVN3u3buDazZtivvg5+effz645sorr4ya66GHHoqqmzdvXnDN5s2bg2tClpvTnl8kUQq/SKIUfpFE5fHR3f3M7DkzezSPhkSkHHns+b9IZbUeEXkbafRz+0cBfwLcnU87IlKWRvf8/wh8FYj7MDoROWkaWbTjY8A+d//NCcb9fq2+zs7O2OlEJGeNLtpxvZm1AYuoLN7xH70HVa/VN2TIkAamE5E8NbJE99fcfZS7jwFuAn7l7p/KrTMRKZRe5xdJVC7v7Xf3J4An8vhdIlIO7flFEmXuXtpkQ4YM8QkTJgTXnXvuucE1l112WXANQGXl8TCxBzLffPPNqLrhw4cH17S1tUXN1doa9/6tbdu2BdfMnDkzaq6YV5Fiz1Y866yzouo2bNgQXLNixYqoeTo7O+v6I9aeXyRRCr9IohR+kUQp/CKJUvhFEqXwiyRK4RdJlMIvkiiFXyRRCr9IohR+kUQp/CKJUvhFElXqWn0QtxZeS0tLcE1zc3NwDcC4ceOCa2LWpQNYuHBhVN2ll14aXBNzJiBA7FmfMWsDrlq1Kmquiy66KLjmtddei5rrkUceiaq78cYbg2ti1hMMOXtTe36RRCn8IolS+EUS1eiKPcPN7Cdm9ryZtZrZlLwaE5FiNXrA75+Ape7+CTNrAk7LoScRKUF0+M1sGPBh4BYAd+8CuvJpS0SK1sjD/rHAK8C/ZUt0321mg3sPql6uq7u7u4HpRCRPjYS/PzAR+KG7XwYcBOb1HlS9XNeAAQMamE5E8tRI+HcBu9x9ZfbzT6j8ZyAibwONrNXXDrxkZu/NrroK2JRLVyJSuEaP9s8F7s+O9G8DPt14SyJShobC7+5rgEn5tCIiZSp1ua6Wlha/+uqrg+tilsOKXY4pZgmtUaNGRc0Vu+3feOON4JqYk18ApkyJe9/WokWLgmtiDwg/+OCDwTWzZ8+Omitm2S2I+3vcv39/cM3Pf/5zXn31VS3XJSK1KfwiiVL4RRKl8IskSuEXSZTCL5IohV8kUQq/SKIUfpFEKfwiiVL4RRKl8IskSuEXSVSpy3X179+fM844I7guZumtmDPfAHbs2BFcM2LEiKi5YpcUi1lqau/evVFzzZ8/P6quo6MjuGbkyJFRc82aNSu4ZvHixVFzxZ4tumvXruCaGTNmBNc8/vjjdY/Vnl8kUQq/SKIUfpFENbpc11+Z2UYz22BmC81sUF6NiUixosNvZucAfwlMcveLgX7ATXk1JiLFavRhf3+g2cz6U1mn7+XGWxKRMjTyuf27gX8AdgJ7gAPuvqz3uOrlun7729/GdyoiuWrkYf/pwEwqa/aNBAab2ad6j6teriv2dW0RyV8jD/uvBra7+yvu3g38FPhAPm2JSNEaCf9O4AozO83MjMpyXa35tCUiRWvkOf9KKotzrgbWZ7/rrpz6EpGCNbpc1+3A7Tn1IiIl0jv8RBJV6ll9w4YN47rrrguua20NP5SwZs2a4BqACy+8MLhm+/btUXMNGhT3hsjRo0cH1/zgBz+ImusrX/lKVN22bduCa2LOfAM4//zzg2tizt4EuP32uAe6TzzxRHDNSy+9FFzT1dVV91jt+UUSpfCLJErhF0mUwi+SKIVfJFEKv0iiFH6RRCn8IolS+EUSpfCLJErhF0mUwi+SqFJP7Ono6GDp0qXBdevXrw+u+dCHPhRcA3HLfB05ciRqrp6enqi6MWPGBNd88pOfjJqrvb09qu4d7wjfr8Qu1zVlypSouhgtLS1RdTt37gyuOXToUHBNd3d33WO15xdJlMIvkiiFXyRRJwy/md1jZvvMbEPVdS1mttzMtmTfTy+2TRHJWz17/nuB6b2umwf80t3fA/wy+1lE3kZOGH53fxLY3+vqmcCC7PICYFa+bYlI0WKf849w9z3Z5XZgRK2BWq5L5NTU8AE/d3fAj3O7lusSOQXFhn+vmZ0NkH3fl19LIlKG2PAvBuZkl+cAP8unHREpSz0v9S0Engbea2a7zOyzwLeAPzazLVQW7PxWsW2KSN5O+N5+d7+5xk1X5dyLiJRI7/ATSVSpZ/WNHj2aO+64I7guZqmp2LPRXn/99eCayZMnR83V1tYWVTd//vzgmrlz50bNtWjRoqi6mJd1Y8/EXLhwYXDN+973vqi5Ys60A6i8KBamqakpuMbM6h6rPb9IohR+kUQp/CKJUvhFEqXwiyRK4RdJlMIvkiiFXyRRCr9IohR+kUQp/CKJUvhFElXqiT2vvPIKP/rRj4LrDh8+HFyzbNmy4BqAiy++OLjm8ssvj5rr6aefjqobMaLmRybWtGTJkqi55syZc+JBffjmN78ZVRdj4sSJpc0Ve6LTjBkzgmu2b98eXNOvX7+6x2rPL5IohV8kUQq/SKJil+v6jpk9b2brzOxhMxteaJcikrvY5bqWAxe7+3jgBeBrOfclIgWLWq7L3Ze5e0/24wpgVAG9iUiB8njO/xngsVo3Vi/X1dnZmcN0IpKHhsJvZrcBPcD9tcZUL9c1ZMiQRqYTkRxFv8nHzG4BPgZc5TEfTSoiJ1VU+M1sOvBV4Ep3j/ssYxE5qWKX6/oXYCiw3MzWmNmdBfcpIjmLXa7rxwX0IiIl0jv8RBJV6ll9XV1d7NixI7hu1qxZwTUxS3wBXHjhhcE1GzZsOPGgPjQ3N0fVzZ49O7jmmWeeiZrrscdqvop7XDfeeGNwTexLwb/+9a+Da/bv33/iQX14//vfH1U3bNiw4JrNmzcH17z55pt1j9WeXyRRCr9IohR+kUQp/CKJUvhFEqXwiyRK4RdJlMIvkiiFXyRRCr9IohR+kUQp/CKJUvhFElXqWX0DBgxg5MiRwXV33313cM2UKVOCawBefPHF4JqDBw9GzRWzBiHA7t27g2t6enpOPKgPt956a1RdV1dXcM3NN/f10REnNnfu3OCa9vb2qLkGDhwYVbdly5bgmvHjxwfXbNy4se6x2vOLJErhF0lU1HJdVbd92czczM4spj0RKUrscl2Y2WhgGrAz555EpARRy3Vlvkfl47v1mf0ib0NRz/nNbCaw293X1jFWy3WJnIKCX+ozs9OAv6HykP+E3P0u4C6Ac889V48SRE4RMXv+ccBYYK2ZtVFZoXe1mb0rz8ZEpFjBe353Xw+cdfTn7D+ASe7+vzn2JSIFi12uS0Te5mKX66q+fUxu3YhIafQOP5FEmXt5B+DNLGqyO+8MXwQ45kQKgNdffz24pqOjI2qu2BNZHnnkkeCa5557Lmqu6dPf8v6uuqxcuTK45uMf/3jUXDEnLb3wwgtRc7366qtRdeecc05wzVNPPRVcs2nTJg4ePGj1jNWeXyRRCr9IohR+kUQp/CKJUvhFEqXwiyRK4RdJlMIvkiiFXyRRCr9IohR+kUQp/CKJUvhFElX2WX2vADtq3HwmcCp8GpD6OJb6ONap3sd57v4H9fyCUsN/PGa2yt0nqQ/1oT7K6UMP+0USpfCLJOpUCv9dJ7uBjPo4lvo41v+bPk6Z5/wiUq5Tac8vIiVS+EUSVWr4zWy6mW02s61mNq+P2wea2QPZ7SvNbEwBPYw2s8fNbJOZbTSzL/Yx5iNmdsDM1mRff5t3H1VztZnZ+myeVX3cbmZ2R7ZN1pnZxJznf2/Vv3ONmXWY2Zd6jSlse5jZPWa2z8w2VF3XYmbLzWxL9v30GrVzsjFbzGxOAX18x8yez7b7w2Y2vEbtce/DHPr4hpntrtr+19aoPW6+3sLdS/kC+gEvAu8GmoC1wEW9xvw5cGd2+SbggQL6OBuYmF0eCrzQRx8fAR4tabu0AWce5/ZrgccAA64AVhZ8H7VTeaNIKdsD+DAwEdhQdd3fA/Oyy/OAb/dR1wJsy76fnl0+Pec+pgH9s8vf7quPeu7DHPr4BvDXddx3x81X768y9/yTga3uvs3du4BFwMxeY2YCC7LLPwGuMrO6PoO8Xu6+x91XZ5ffAFqB8A9VL89M4N+9YgUw3MzOLmiuq4AX3b3WuzBz5+5PAvt7XV39d7AAmNVH6TXAcnff7+6vAcuBuEUGavTh7svc/eiiACuoLEpbqBrbox715OsYZYb/HOClqp938dbQ/X5MttEPAGcU1VD2tOIyoK8VJqaY2Voze8zM/rCoHgAHlpnZb8zs833cXs92y8tNwMIat5W1PQBGuPue7HI7MKKPMWVuF4DPUHkE1pcT3Yd5+EL29OOeGk+DgrdHsgf8zGwI8BDwJXfvveTOaioPfS8F/hn4rwJb+aC7TwRmAH9hZh8ucK6azKwJuB74zz5uLnN7HMMrj2lP6uvRZnYb0APcX2NI0ffhD4FxwARgDzA/j19aZvh3A6Orfh6VXdfnGDPrDwwD4tZHOg4zG0Al+Pe7+0973+7uHe7emV1eAgwwszPz7iP7/buz7/uAh6k8fKtWz3bLwwxgtbvv7aPH0rZHZu/RpzbZ9319jCllu5jZLcDHgD/N/iN6izruw4a4+153P+zuR4B/rfH7g7dHmeF/FniPmY3N9jI3AYt7jVkMHD1q+wngV7U2eKzsGMKPgVZ3/26NMe86eqzBzCZT2U5F/Cc02MyGHr1M5QDThl7DFgOzs6P+VwAHqh4S5+lmajzkL2t7VKn+O5gD/KyPMb8AppnZ6dnD4GnZdbkxs+nAV4Hr3f1QjTH13IeN9lF9jOeGGr+/nnwdK48jlAFHMq+lcnT9ReC27Lq/o7JxAQZRedi5FXgGeHcBPXyQysPIdcCa7Ota4Fbg1mzMF4CNVI6YrgA+UND2eHc2x9psvqPbpLoXA76fbbP1wKQC+hhMJczDqq4rZXtQ+Q9nD9BN5XnqZ6kc5/klsAX4b6AlGzsJuLuq9jPZ38pW4NMF9LGVyvPoo38nR1+JGgksOd59mHMf92X3/ToqgT67dx+18nW8L729VyRRyR7wE0mdwi+SKIVfJFEKv0iiFH6RRCn8IolS+EUS9X/Aa62+qXCM1gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "A = np.round(np.random.random((8,8)))\n",
    "\n",
    "\n",
    "num_samples_per_epoch = 2048\n",
    "batch_size = 64\n",
    "data_loader = get_epoch_data_loader_new(num_samples_per_epoch, batch_size, mat_dim)\n",
    "for batch_id, (real, rtarget) in enumerate(data_loader()):\n",
    "    if batch_id == 0:\n",
    "        print(real.shape,rtarget.shape)\n",
    "        plt.figure()\n",
    "        plt.imshow(real[0], cmap=plt.cm.gray)\n",
    "        plt.figure()\n",
    "        plt.imshow(rtarget[0], cmap=plt.cm.gray)\n",
    "        test = models[1]\n",
    "        noise1 = torch.randn(1, z_dim)\n",
    "        noise = torch.cat((noise1, rtarget[0].view(1,-1)), dim=1)\n",
    "        gen = test(noise)\n",
    "        plt.figure()\n",
    "        plt.imshow(gen.detach().numpy().reshape(16,16), cmap=plt.cm.gray)\n",
    "        \n",
    "\n",
    "    else: \n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([4, 4]) torch.Size([16]) tensor(7.5000)\n",
      "tensor([ 7.5000,  7.5000,  5.0000,  0.0000,  5.0000, 10.0000,  2.5000,  5.0000,\n",
      "        10.0000,  2.5000,  2.5000,  0.0000,  2.5000,  2.5000,  0.0000,  0.0000]) torch.Size([2048, 16])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 1. Got 64 and 2048 in dimension 0 (The offending index is 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-9c5c4985ab09>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;31m#rtarget = true_post\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;31m#testinp = torch.cat((noise1, rtarget.view(testing_x_per_y,-1)), dim=1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mtestinp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnoise1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2048\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0msamples1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestinp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 1. Got 64 and 2048 in dimension 0 (The offending index is 1)"
     ]
    }
   ],
   "source": [
    "for i, y in enumerate(testing_ys):\n",
    "    print(i, y.shape, y.flatten().shape, y.flatten()[0])\n",
    "\n",
    "    #true_posterior_params = get_mixture_posterior(mixture_params, forward_map, b**2 * torch.eye(DIMENSION, device=device), y)\n",
    "    #true_posterior_samples = draw_mixture_dist(true_posterior_params, testing_x_per_y).cpu().numpy()\n",
    "    true_posterior_samples = draw_mats_post(y)\n",
    "    inflated_ys = y.flatten()[None, :].repeat(2048, 1)\n",
    "    print(y.flatten(), inflated_ys.shape)\n",
    "    true_post = true_posterior_samples.reshape(-1, 16)\n",
    "    noise1 = torch.randn(true_post.shape[0], 16).to(device)\n",
    "    rtarget = inflated_ys\n",
    "    #rtarget = true_post\n",
    "    #testinp = torch.cat((noise1, rtarget.view(testing_x_per_y,-1)), dim=1)\n",
    "    testinp = torch.cat((noise1, rtarget.view(2048,-1)), dim=1)\n",
    "\n",
    "    samples1 = models[1](testinp).detach().cpu().numpy()\n",
    "    print(samples1, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.choice(90, 3)\n",
    "'''\n",
    "bereits probiert:\n",
    "6 layer crit\n",
    "8 layer crit\n",
    "6 layer gen\n",
    "1000 epochs\n",
    "same same but 4048 samples\n",
    "0.2 lrelu\n",
    "training data torch.Size([64, 64, 64]) torch.Size([64, 32, 32])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([   [ [1],[2],[3] ], [ [4],[5],[6] ]   ])\n",
    "print(x)\n",
    "print(x[:,:])\n",
    "print(x[...,0])\n",
    "print(x[...])\n",
    "print(x[0,...])\n",
    "print(x[1,...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = draw_mixture_dist(mixture_params, testing_num_y)\n",
    "print(x.shape)\n",
    "print(x[:,0])\n",
    "plt.hist(x[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q25, q75 = np.percentile(x,[.25,.75])\n",
    "bin_width = 2*(q75 - q25)*len(x)**(-1/3)\n",
    "bins = round((x.max() - x.min())/bin_width)\n",
    "print(\"Freedman–Diaconis number of bins:\", bins)\n",
    "plt.hist(x, bins = bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-66-814638d9f3da>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpytorch_total_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = create_GAN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "154432"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in models[1].parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(models[1].state_dict(), r'C:\\Users\\Karl\\TUB\\Master Thesis\\gen_toy_5dim_1000epochs.pt')\n",
    "torch.save(models[0].state_dict(), r'C:\\Users\\Karl\\TUB\\Master Thesis\\crit_toy_5dim_1000epochs.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Computing Wasserstein distances:   0%|          | 0/100 [00:43<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 64)\n",
      "[[0. 0. 0. ... 1. 0. 1.]\n",
      " [0. 1. 0. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 1. ... 0. 0. 1.]\n",
      " [0. 0. 1. ... 1. 0. 1.]\n",
      " [1. 0. 1. ... 0. 0. 0.]] A\n",
      "torch.Size([32, 32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 2.,  ..., 1., 3., 3.],\n",
       "        [2., 1., 1.,  ..., 3., 1., 3.],\n",
       "        [3., 2., 2.,  ..., 1., 2., 1.],\n",
       "        ...,\n",
       "        [1., 3., 2.,  ..., 3., 2., 1.],\n",
       "        [1., 2., 3.,  ..., 3., 1., 3.],\n",
       "        [1., 4., 2.,  ..., 0., 1., 1.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.tensor([[1, 1, 1, 0], [1, 1, 0, 0], [1, 1, 0, 0], [1, 0, 1, 1]])\n",
    "A = torch.tensor([[1,1,1],[0,1,1],[1,1,1], [0,1,0]])\n",
    "A = np.round(np.random.random((64,64)))\n",
    "#A = torch.zeros(10,10)\n",
    "print(A.shape)\n",
    "if A.shape[1]%2 == 1:\n",
    "    A = torch.hstack((A, torch.zeros(A.shape[0],1)))\n",
    "if A.shape[0]%2 == 1:\n",
    "    A = torch.vstack((A, torch.zeros(A.shape[1])))\n",
    "print(A,'A')\n",
    "i, j = 0, 0\n",
    "stride = 2\n",
    "c = torch.zeros(A.shape[0]//stride, A.shape[1]//stride)\n",
    "print(c.shape)\n",
    "for _ in range(A.shape[0]):\n",
    "    for _ in range(A.shape[1]):\n",
    "        if i%2 == 0 and j%2 == 0:\n",
    "            try:\n",
    "                c[i//2, j//2] += A[i, j]\n",
    "                c[i//2, j//2] += A[i+1, j]\n",
    "                c[i//2, j//2] += A[i, j+1]\n",
    "                c[i//2, j//2] += A[i+1, j+1]\n",
    "            except:\n",
    "                print('oh noez', i,j)\n",
    "        i += 1\n",
    "        if i >= A.shape[0]:\n",
    "            i = 0\n",
    "    j += 1\n",
    "    if j >= A.shape[1]:\n",
    "            j = 0\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1.6162]]]]) tensor([[[[ 0.9431, -0.0556,  0.2256,  0.7043],\n",
      "          [ 1.1304,  1.2765,  0.4348,  0.0962],\n",
      "          [ 1.6162, -0.6228,  0.4553,  0.6678],\n",
      "          [ 1.2643, -1.1986,  0.1698, -1.4295]]]])\n"
     ]
    }
   ],
   "source": [
    "m = nn.MaxPool2d(3, stride=2)\n",
    "input = torch.randn(1, 1, 4, 4)\n",
    "output = m(input)\n",
    "print(output, input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#c = torch.tensor([[1,4], [1,2]])\n",
    "#c = A\n",
    "def build_candidates(c):\n",
    "    candidates = []\n",
    "    cand = []\n",
    "    for m,row in enumerate(c):\n",
    "        for n,i in enumerate(row):\n",
    "            if int(i) == 0 or int(i) == 4:\n",
    "                cand += [torch.tensor([[i * 0.25, i * 0.25], [i * 0.25, i * 0.25]])]\n",
    "            elif int(i) == 1:\n",
    "                cand += [torch.tensor([[1, 0], [0, 0]])]\n",
    "                cand += [torch.tensor([[0, 1], [0, 0]])]\n",
    "                cand += [torch.tensor([[0, 0], [1, 0]])]\n",
    "                cand += [torch.tensor([[0, 0], [0, 1]])]\n",
    "            elif int(i) == 2:\n",
    "                cand += [torch.tensor([[1, 1], [0, 0]])]\n",
    "                cand += [torch.tensor([[0, 0], [1, 1]])]\n",
    "                cand += [torch.tensor([[1, 0], [1, 0]])]\n",
    "                cand += [torch.tensor([[0, 1], [0, 1]])]\n",
    "                cand += [torch.tensor([[1, 0], [0, 1]])]\n",
    "                cand += [torch.tensor([[0, 1], [1, 0]])]\n",
    "            else:\n",
    "                cand += [torch.tensor([[1, 1], [1, 0]])]\n",
    "                cand += [torch.tensor([[1, 1], [0, 1]])]\n",
    "                cand += [torch.tensor([[1, 0], [1, 1]])]\n",
    "                cand += [torch.tensor([[0, 1], [1, 1]])]\n",
    "\n",
    "            candidates += [cand]\n",
    "            cand = []\n",
    "    return candidates\n",
    "#print(candidates)\n",
    "'''\n",
    "fin = []\n",
    "for i in candidates[0]:\n",
    "    for j in candidates[1]:\n",
    "        for k in candidates[2]:\n",
    "            for l in candidates[3]:\n",
    "                \n",
    "                upperb = np.hstack((i, j))\n",
    "                lowerb = np.hstack((k, l))\n",
    "                f = np.vstack((upperb, lowerb))\n",
    "                fin += [f]\n",
    "print(len(fin))\n",
    "for i in fin:\n",
    "    print(i)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.vstack((torch.ones(3,4),torch.zeros(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates = build_candidates(c)\n",
    "fins = build_mat(candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mat(candidates):\n",
    "    fin = []\n",
    "    for i in candidates[0]:\n",
    "        for j in candidates[1]:\n",
    "            for k in candidates[2]:\n",
    "                for l in candidates[3]:\n",
    "                    \n",
    "                    upperb = np.hstack((i, j))\n",
    "                    lowerb = np.hstack((k, l))\n",
    "                    f = np.vstack((upperb, lowerb))\n",
    "                    fin += [f]\n",
    "    return torch.tensor(fin)\n",
    "    \n",
    "def split(c):\n",
    "    cs = []\n",
    "    i,j = 0,0\n",
    "    for _ in range(c.shape[0]):\n",
    "        for _ in range(c.shape[1]):\n",
    "            if i%2 == 0 and j%2 == 0:\n",
    "                try:\n",
    "                    chat = c[i:i+2, j:j+2]\n",
    "                    cs += [chat]\n",
    "                except:\n",
    "                    print('oh noez', i,j)\n",
    "            i += 1\n",
    "            if i >= A.shape[0]:\n",
    "                i = 0\n",
    "        j += 1\n",
    "        if j >= A.shape[1]:\n",
    "                j = 0\n",
    "    return cs\n",
    "\n",
    "def divide(box):\n",
    "    \n",
    "    m = box.shape[0]\n",
    "    n = box.shape[1]\n",
    "    box1 = box[0:m//2, 0:n//2]\n",
    "    box2 = box[0:m//2, n//2:]\n",
    "    box3 = box[m//2:, 0:n//2]\n",
    "    box4 = box[m//2:, n//2:]\n",
    "    \n",
    "    return [box1, box2, box3, box4]\n",
    "nest_level = 2\n",
    "act_level = 0\n",
    "def nested(act_level, nest_level, box):\n",
    "    if act_level == nest_level:\n",
    "        return box\n",
    "    else:\n",
    "        act_level += 1\n",
    "        box = divide(box)\n",
    "        return nested(act_level, nest_level, box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finss = []\n",
    "rowc = []\n",
    "i,j = 0,0\n",
    "for chat in splitted:\n",
    "    candidates = build_candidates(chat)\n",
    "    fins = build_mat(candidates)\n",
    "    finss += [fins]\n",
    "    i += 1\n",
    "    if i > 1:\n",
    "        for mats1 in finss[0]:\n",
    "            for mats2 in finss[1]:\n",
    "                rowc += [np.vstack(mats1, mats2)]\n",
    "        finss = []\n",
    "        j += 1\n",
    "        i = 0\n",
    "    if j >= c.shape[0] // 2:\n",
    "        \n",
    "                \n",
    "            \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "math.factorial(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_candidates_shallow():\n",
    "    if end:\n",
    "        candidates = build_candidates_deep\n",
    "        fins = build_mat(candidates)\n",
    "        return fins\n",
    "    else:\n",
    "        candidates = build_candidates_shallow\n",
    "        fins = build_mat(candidates)\n",
    "        return fins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in boxlist:\n",
    "    if type(element) is list:\n",
    "        return func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "64*864*576*864"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fins = []\n",
    "c = np.array([[2,2],[2,2]])\n",
    "candidates = build_candidates(c)\n",
    "fin = build_mat(candidates)\n",
    "print(fin.reshape(-1, 16).shape)\n",
    "\n",
    "\n",
    "if False:\n",
    "    for boxxx in divide(c):\n",
    "        candidates = build_candidates(boxxx)\n",
    "        fin = build_mat(candidates)\n",
    "        fins += [fin]\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nest_level = 2\n",
    "act_level = 0\n",
    "def nested(act_level, nest_level, box):\n",
    "    if act_level == nest_level:\n",
    "        return divide(box)\n",
    "    else:\n",
    "        act_level += 1\n",
    "        try:\n",
    "            box = divide(box)\n",
    "        except:\n",
    "            \n",
    "            return nested(act_level, nest_level, box[act_level])\n",
    "print(nested(act_level, nest_level, c))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tuples(depth, n, start=0):\n",
    "    if depth == 0:\n",
    "        yield ()\n",
    "    else:\n",
    "        for x in range(start, n):\n",
    "            for t in make_tuples(depth - 1, n, x + 1):\n",
    "                yield (x,) + t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (i1, i2, i3) in make_tuples(3, 10):\n",
    "\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = 1\n",
    "def rec(box, init, divs=[]):\n",
    "    if init == 1:\n",
    "        init = 0\n",
    "        divs = []\n",
    "    if type(box) is list:\n",
    "        for b in box:\n",
    "            print(b)\n",
    "            divs.append([rec(b, init, divs)])\n",
    "    else:\n",
    "        box = divide(box)\n",
    "        \n",
    "        return rec(box, init)\n",
    "    \n",
    "    return divs\n",
    "\n",
    "print(rec(c, init))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.tensor(np.array([[2,1],[2,4]]))\n",
    "w = torch.cat([w,w])\n",
    "print(w)\n",
    "print(w.reshape(-1,2,2))\n",
    "w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.tensor(np.array([[2,1],[2,4]]))\n",
    "\n",
    "w[None, :].repeat(8, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = get_epoch_data_loader_new(1000, 32)\n",
    "for batch_id, (real, rtarget) in enumerate(h()):\n",
    "    print(batch_id, real.shape, rtarget.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.tensor([[1,2],[3,4]])\n",
    "yy = y[None, :].repeat(10, 1)\n",
    "yy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_mats(num_samples, shape=4):\n",
    "    return torch.tensor(np.round(np.random.rand(num_samples, shape, shape)), dtype=torch.float32)\n",
    "\n",
    "def count(A, stride=2):\n",
    "    i, j = 0, 0\n",
    "    M, N = A.shape[0], A.shape[1]\n",
    "   \n",
    "    c = torch.zeros(M//stride, N//stride)\n",
    "    for _ in range(M):\n",
    "        for _ in range(N):\n",
    "            if i%2 == 0 and j%2 == 0:\n",
    "                \n",
    "                c[i//2, j//2] += A[i, j]\n",
    "                c[i//2, j//2] += A[i+1, j]\n",
    "                c[i//2, j//2] += A[i, j+1]\n",
    "                c[i//2, j//2] += A[i+1, j+1]\n",
    "                \n",
    "            i += 1\n",
    "            if i >= M:\n",
    "                i = 0\n",
    "        j += 1\n",
    "        if j >= N:\n",
    "                j = 0\n",
    "    return torch.tensor(c, dtype=torch.float32)\n",
    "def forward_mat(x):\n",
    "    mats = torch.tensor([])\n",
    "    for i in range(x.shape[0]):\n",
    "        mats = torch.cat((mats, count(x[i])))        \n",
    "    return mats.reshape(x.shape[0], x.shape[1]//2, x.shape[1]//2)\n",
    "def get_epoch_data_loader_new(num_samples_per_epoch, batch_size):\n",
    "    x = draw_mats(num_samples_per_epoch)\n",
    "    y = forward_mat(x)\n",
    "    def epoch_data_loader_new():\n",
    "        for i in range(0, num_samples_per_epoch, batch_size):\n",
    "            yield x[i:i+batch_size].clone(), y[i:i+batch_size].clone()\n",
    "\n",
    "    return epoch_data_loader_new\n",
    "def build_candidates(c):\n",
    "    candidates = []\n",
    "    cand = []\n",
    "    for m,row in enumerate(c):\n",
    "        for n,i in enumerate(row):\n",
    "            if int(i) == 0 or int(i) == 4:\n",
    "                cand += [torch.tensor([[i * 0.25, i * 0.25], [i * 0.25, i * 0.25]])]\n",
    "            elif int(i) == 1:\n",
    "                cand += [torch.tensor([[1, 0], [0, 0]])]\n",
    "                cand += [torch.tensor([[0, 1], [0, 0]])]\n",
    "                cand += [torch.tensor([[0, 0], [1, 0]])]\n",
    "                cand += [torch.tensor([[0, 0], [0, 1]])]\n",
    "            elif int(i) == 2:\n",
    "                cand += [torch.tensor([[1, 1], [0, 0]])]\n",
    "                cand += [torch.tensor([[0, 0], [1, 1]])]\n",
    "                cand += [torch.tensor([[1, 0], [1, 0]])]\n",
    "                cand += [torch.tensor([[0, 1], [0, 1]])]\n",
    "                cand += [torch.tensor([[1, 0], [0, 1]])]\n",
    "                cand += [torch.tensor([[0, 1], [1, 0]])]\n",
    "            else:\n",
    "                cand += [torch.tensor([[1, 1], [1, 0]])]\n",
    "                cand += [torch.tensor([[1, 1], [0, 1]])]\n",
    "                cand += [torch.tensor([[1, 0], [1, 1]])]\n",
    "                cand += [torch.tensor([[0, 1], [1, 1]])]\n",
    "\n",
    "            candidates += [cand]\n",
    "            cand = []\n",
    "    return candidates\n",
    "\n",
    "def draw_mats_post(y):\n",
    "    fin = []\n",
    "    candidates = build_candidates(y)\n",
    "    for i in candidates[0]:\n",
    "        for j in candidates[1]:\n",
    "            for k in candidates[2]:\n",
    "                for l in candidates[3]:\n",
    "                    \n",
    "                    upperb = np.hstack((i, j))\n",
    "                    lowerb = np.hstack((k, l))\n",
    "                    f = np.vstack((upperb, lowerb))\n",
    "                    fin += [f]\n",
    "    return torch.tensor(fin, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_candidates_ind(c):\n",
    "    candidates = []\n",
    "    cand = []\n",
    "    for m,row in enumerate(c):\n",
    "        for n,i in enumerate(row):\n",
    "            if int(i) == 0:\n",
    "                cand += [np.array([])]\n",
    "            elif int(i) == 1:\n",
    "                cand += [np.array([(0,0)])]\n",
    "                cand += [np.array([(0,1)])]\n",
    "                cand += [np.array([(1,0)])]\n",
    "                cand += [np.array([(1,1)])]\n",
    "            elif int(i) == 2:\n",
    "                cand += [np.array([(0,0), (0,1)])]\n",
    "                cand += [np.array([(1,0), (1,1)])]\n",
    "                cand += [np.array([(0,0), (1,0)])]\n",
    "                cand += [np.array([(0,1), (1,1)])]\n",
    "                cand += [np.array([(0,0), (1,1)])]\n",
    "                cand += [np.array([(0,1), (1,0)])]\n",
    "            elif int(i) == 3:\n",
    "                cand += [np.array([(0,0), (0,1), (1,0)])]\n",
    "                cand += [np.array([(0,0), (0,1), (1,1)])]\n",
    "                cand += [np.array([(0,0), (1,0), (1,1)])]\n",
    "                cand += [np.array([(0,1), (1,0), (1,1)])]\n",
    "            else:\n",
    "                cand += [np.array([(0,0), (0,1), (1,0), (1,1)])]\n",
    "\n",
    "            candidates += [cand]\n",
    "            cand = []\n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_from_2x2(c, mat, m=0, n=0):\n",
    "    for k, build_list in enumerate(build_candidates_ind(c)):\n",
    "    \n",
    "        r_ind = np.random.choice(len(build_list))\n",
    "        indicees = build_list[r_ind]\n",
    "        for index in indicees:\n",
    "            i = index[0]\n",
    "            j = index[1]\n",
    "            if k == 0:\n",
    "                mat[i+m, j+n] = 1\n",
    "            elif k == 1:\n",
    "                mat[i+m, j + 2 + n] = 1\n",
    "            elif k == 2:\n",
    "                mat[i + 2 + m, j+n] = 1\n",
    "            else:\n",
    "                mat[i+2+m, j+2+n] = 1\n",
    "    return mat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct(shape, c):\n",
    "    splitted = split(c)\n",
    "    mat = np.zeros(shape)\n",
    "    m = 0\n",
    "    i, j = 0,0\n",
    "    for splitt in splitted:\n",
    "        mat = build_from_2x2(splitt, mat, i,j)\n",
    "\n",
    "        i += 4\n",
    "        m += 1\n",
    "\n",
    "        if m > 0 and m%int(shape/4) == 0:\n",
    "            j += 4\n",
    "            i = 0\n",
    "            m = 0\n",
    "            \n",
    "    return mat\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.array([(1,1), (2,2), (2,1)]):\n",
    "    print(i+10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.zeros((23,23))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_block(candidates, num_samples=1):\n",
    "    blockmatrices = []\n",
    "    for i in range(num_samples):\n",
    "        block = []\n",
    "        \n",
    "        for build_list in candidates:\n",
    "            \n",
    "            ind = np.random.choice(len(build_list))\n",
    "            block += [build_list[ind]]\n",
    "        upperb = np.hstack((block[0], block[1]))\n",
    "        lowerb = np.hstack((block[2], block[3]))\n",
    "        blockM = np.vstack((upperb, lowerb))\n",
    "        blockmatrices += [blockM]\n",
    "    return blockmatrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_big_block(blocks, num_samples=1):\n",
    "    bb = []\n",
    "    i = 0\n",
    "    for i in range(num_samples):\n",
    "        block = []\n",
    "        \n",
    "        while i < 4:\n",
    "            i += 1\n",
    "            ind = np.random.choice(len(blocks))\n",
    "            block += [blocks[ind]]\n",
    "        upperb = np.hstack((block[0], block[1]))\n",
    "        lowerb = np.hstack((block[2], block[3]))\n",
    "        blockM = np.vstack((upperb, lowerb))\n",
    "        bb += [blockM]\n",
    "    return bb\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.tensor([[1,2], [4,2]])\n",
    "c = build_candidates(y)\n",
    "m = build_block(c, 4)\n",
    "print(m)\n",
    "p = build_big_block(m, 1)\n",
    "#print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ma = np.array([[1,2],[3,4]])\n",
    "ma[(0,0), (1,1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "li = [(1,2),(3,4)]\n",
    "li[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "16/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "        data_loader = get_epoch_data_loader_new(2048, 64, 64)\n",
    "        print('t')\n",
    "        loss = gl(models, data_loader, opt_gen, opt_crit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.AvgPool2d(2, stride=(2,2))\n",
    "inp = 10*torch.tensor(np.round(np.random.rand(2, 64, 64)), dtype=torch.float32)\n",
    "print(inp)\n",
    "output = m(inp)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = create_GAN(mat_dim, z_dim)\n",
    "sum(p.numel() for p in models[1].parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
